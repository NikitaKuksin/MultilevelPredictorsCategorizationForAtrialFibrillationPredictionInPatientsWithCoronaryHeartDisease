{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D1KEANfbdhmS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "import datetime\n",
        "\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate,  KFold, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report , matthews_corrcoef\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_curve, auc, ConfusionMatrixDisplay, RocCurveDisplay\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import itertools\n",
        "import math\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras import utils\n",
        "from keras.metrics import AUC\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import regularizers\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%config InlineBackend.figure_format = 'png'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXRvtq-HdhmW",
        "outputId": "30cb28a0-39d6-4f7c-f06c-fe9f6865c170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1305, 55)\n",
            "Atrial fibrillation\n",
            "0    1025\n",
            "1     280\n",
            "Name: count, dtype: int64\n",
            "Atrial fibrillation\n",
            "0    0.785441\n",
            "1    0.214559\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "## Open dataset\n",
        "data = pd.read_excel(\"DataSet.xlsx\")\n",
        "print(data.shape)\n",
        "## How many POAF and POAF free\n",
        "end_point = 'Atrial fibrillation'\n",
        "print(data[end_point].value_counts(dropna = False))\n",
        "print(data[end_point].value_counts(dropna = False, normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWulCAn1dhmX"
      },
      "source": [
        "### Let's calculate some features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrOxfgXodhmY",
        "outputId": "fdefdd00-8ab3-4f66-d5aa-5f5e2a90e25f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    893.000000\n",
            "mean     166.547678\n",
            "std       43.873711\n",
            "min       51.673995\n",
            "25%      137.164846\n",
            "50%      162.782870\n",
            "75%      190.906383\n",
            "max      364.240741\n",
            "Name: CC, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "######### Сreatinine clearance\n",
        "name = 'CC'\n",
        "data[name] = np.nan\n",
        "data.loc[:,(name)]= (140-data.loc[:,('Age, years')]) * (data.loc[:,('Height, cm')]/(72 * data.loc[:,('Creatinine, µmol/l')] /88.4))\n",
        "data.loc[(data[\"Female\"] == 1),(name)]= data.loc[(data[\"Female\"] == 1),(name)] * 0.85\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysis of features (Table 1)"
      ],
      "metadata": {
        "id": "mvFNJ2m8yQ0d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUkQAYVIdhma"
      },
      "source": [
        "### Analysis of dichotomous features in comparison groups (Table 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYpi-itrdhmb"
      },
      "outputs": [],
      "source": [
        "features=['Female','CHF III-IV FC','Arterial hypertension','Aortic regurgitation','Mitral regurgitation','Tricuspid regurgitation','Extracardiac arteriopathy','Chronic kidney disease','Aortic stenosis','Сhronic obstructive pulmonary disease',\n",
        "            'Diabetes mellitus', 'Previous stroke']\n",
        "\n",
        "for name in features:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Feature analysis: {name}\")\n",
        "\n",
        "    # Descriptive statistics\n",
        "    print(\"Distribution of values:\")\n",
        "\n",
        "    print(data[name].value_counts(dropna=False))\n",
        "\n",
        "    print(\"\\nGrouping by end point  (absolute frequencies):\")\n",
        "    print(data.groupby([end_point])[name].value_counts(dropna=False, normalize=False))\n",
        "\n",
        "    print(\"\\nGrouping by end point (relative frequencies):\")\n",
        "    print(data.groupby([end_point])[name].value_counts(dropna=False, normalize=True))\n",
        "\n",
        "    # Creating a contingency table\n",
        "    ct = pd.crosstab(data[end_point], data[name])\n",
        "\n",
        "    # Fisher's exact test\n",
        "    oddsratio, pvalue_fisher = stats.fisher_exact(ct)\n",
        "    print(f'\\nFishers exact test - Odds ratio: {oddsratio:.4f}, p-value: {pvalue_fisher:.4f}')\n",
        "\n",
        "    # Odds ratio and 95% CI\n",
        "    try:\n",
        "        table = sm.stats.Table2x2(ct, shift_zeros=False)\n",
        "        odds_ratio = table.oddsratio\n",
        "        confint = table.oddsratio_confint()\n",
        "        print(f'Odds ratio: {odds_ratio:.4f}, 95% CI: [{confint[0]:.4f}, {confint[1]:.4f}]')\n",
        "    except Exception as e:\n",
        "        print(f'Error in calculating odds ratio: {e}')\n",
        "\n",
        "    # Chi-square test\n",
        "    try:\n",
        "        chi2, p_chi2, dof, expected = scipy.stats.chi2_contingency(pd.crosstab(data[end_point], data[name]))\n",
        "        print(f\"Chi-square test: p-value = {p_chi2:.4f}\")\n",
        "    except Exception as e:\n",
        "        print(f'Error in calculating Chi-square test: {e}')\n",
        "\n",
        "    # Добавляем небольшую паузу для удобства чтения\n",
        "    print(f\"\\n{'='*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKnHvbrWdhmc"
      },
      "source": [
        "### Analysis of continuous features in comparison groups (Table 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coF_SNmDdhmc"
      },
      "outputs": [],
      "source": [
        "features = ['Age, years', 'Weight, kg', 'Height, cm', 'BMI, kg/m^2', 'EF LV, %', 'RLVMI, c.u.', 'RVAWRTI, c. u.', 'LV ESD, cm', 'LV EDD, cm', 'Systolic pressure gradient Ao/LV, mm Hg', 'MPAP, mm Hg',\n",
        "           'LAL, cm', 'LAD, cm', 'Indexed LA volume, ml/m2', 'RAL, cm', 'RAD, cm', 'P, ms', 'PQ, ms\\n', 'QRS, ms\\n', 'QT, ms\\n', 'Creatinine, µmol/l', 'CC',\n",
        "            \"Hemoglobin, g/l\",\"Red blood cells,10^12/l\",\"Leukocytes,10^9/l\",\"Lymphocytes,10^9/l\",\"Total cholesterol,mmol/l\",\"Glucose, mmol/l\",\"Total protein, g/l\",\"Total bilirubin, µmol/l\",\"Triglycerides, mmol/l\",\"Urea, mmol/l\",\"DBP, mm Hg\",\"PTI, %\",\"INR\",\"Platelets,10^9/l\",\"SBP, mm Hg\",\"DBP, mm Hg\",\"Heart rate, beats/min\"\n",
        "]\n",
        "\n",
        "\n",
        "for name in features:\n",
        "\n",
        "  print(f\"\\n{'='*60}\")\n",
        "  print(f\"Feature analysis: {name}\")\n",
        "\n",
        "  n1 = data.loc[(data[end_point] == 0), (name)].astype(float).dropna()\n",
        "  n2 = data.loc[(data[end_point] == 1), (name)].astype(float).dropna()\n",
        "\n",
        "  print('Mann-Whitney =  %.26f' %  scipy.stats.mannwhitneyu(n1, n2).pvalue)\n",
        "  print(data[name].dropna().describe())\n",
        "  print(data.groupby([end_point])[name].describe())\n",
        "\n",
        "  sns.boxplot(x=end_point, y=name, data=data)\n",
        "  plt.xlabel(\"POAF\")\n",
        "  plt.ylabel( name )\n",
        "  plt.show()\n",
        "\n",
        "  print(f\"\\n{'='*60}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Development of models based on continuous variables (Table 2)\n",
        "\n"
      ],
      "metadata": {
        "id": "t5DsW0c3pldN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preparation\n",
        "features =[ 'Age, years',  'RAD, cm' , 'Tricuspid regurgitation' ,  'QRS, ms\\n' , 'QT, ms\\n', 'RR, ms\\n' ,'PQ, ms\\n', 'P, ms' ,  'LV ESD, cm'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10"
      ],
      "metadata": {
        "id": "Qh6TgYvaqun4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Logistic regression (Table 2)\n"
      ],
      "metadata": {
        "id": "ph306kBjC58v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "TBupU8rxdhmf"
      },
      "outputs": [],
      "source": [
        "np.random.seed(rm)\n",
        "border = 0.195\n",
        "\n",
        "########### Logistic regression\n",
        "max_iter = 10000\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "\n",
        "for j in range(100):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "    # We set aside 20% for final testing\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data[features],model_data[y_name],\n",
        "                                                          train_size=0.8,\n",
        "                                                          stratify=model_data[y_name],\n",
        "                                                          random_state = rm )\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x_validate = np.array(x_validate)\n",
        "    y_validate = utils.to_categorical(y_validate)\n",
        "\n",
        "    roc_auc_test=[]\n",
        "    sen_test=[]\n",
        "    spec_test=[]\n",
        "    matr_test=[]\n",
        "    f1_test=[]\n",
        "    ppv_test=[]\n",
        "    npv_test=[]\n",
        "    threshold_test=[]\n",
        "    skf = StratifiedKFold(n_splits=n_splits )\n",
        "\n",
        "    # training and cross-validation\n",
        "    for i, (train_index, test_index) in enumerate(skf.split(x, y[:,1])):\n",
        "\n",
        "        x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "        y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "        model = LogisticRegression( max_iter=max_iter )\n",
        "\n",
        "        np.random.seed(rm)\n",
        "        model.fit(x_train, y_train[:,1])\n",
        "        y_pred_log=model.predict_proba(x_test)\n",
        "        new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "        new_y = np.array(new_y)\n",
        "        cMatrix = confusion_matrix(y_test[:,1].astype(\"int\"), new_y)\n",
        "        sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "        specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "        sen_test.append(sensivity)\n",
        "        spec_test.append(specifity)\n",
        "        fpr,tpr,thresholds = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_test.append(roc_auc)\n",
        "        f1=f1_score(y_test[:,1], new_y)\n",
        "        f1_test.append(f1)\n",
        "        ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "        npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "        ppv_test.append(ppv)\n",
        "        npv_test.append(npv)\n",
        "\n",
        "    mean_roc_auc_test.append(np.mean(roc_auc_test))\n",
        "    mean_sen_test.append(np.mean(sen_test))\n",
        "    mean_spec_test.append(np.mean(spec_test))\n",
        "    mean_f1_test.append(np.mean(f1_test))\n",
        "    mean_ppv_test.append(np.mean(ppv_test))\n",
        "    mean_npv_test.append(np.mean(npv_test))\n",
        "\n",
        "    model = LogisticRegression( max_iter=max_iter )\n",
        "\n",
        "    np.random.seed(rm)\n",
        "    model.fit(x, y[:,1])\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "    cMatrix = confusion_matrix(y_validate[:,1].astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate[:,1], y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate[:,1], new_y)\n",
        "    ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Mean area under the ROC curve = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_roc_auc_test),\n",
        "                                                                       np.mean (mean_roc_auc_test) -\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test)) ,\n",
        "                                                                       np.mean (mean_roc_auc_test) +\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test) )\n",
        "                                                                             ))\n",
        "print('Mean Sensitivity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen_test),\n",
        "                                                                       np.mean (mean_sen_test) -\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test)) ,\n",
        "                                                                       np.mean (mean_sen_test) +\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test))\n",
        "                                                                               ))\n",
        "print('Mean Specificity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec_test),\n",
        "                                                                       np.mean (mean_spec_test) - 1.96 * np.std(mean_spec_test) /np.sqrt(len(mean_spec_test)),\n",
        "                                                                       np.mean (mean_spec_test) + 1.96 * np.std(mean_spec_test)/np.sqrt(len(mean_spec_test) ))\n",
        "                                                                            )\n",
        "print('Mean F1-score ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1_test),\n",
        "                                                                       np.mean (mean_f1_test) - 1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test)) ,\n",
        "                                                                       np.mean (mean_f1_test) +\n",
        "                                                                       1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean PPV ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv_test),\n",
        "                                                                       np.mean (mean_ppv_test) -\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test)) ,\n",
        "                                                                       np.mean (mean_ppv_test) +\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean NPV  ={:.4f} 95% [ {:.4f}, {:.4f}]'.format(np.mean (mean_npv_test),\n",
        "                                                                   np.mean (mean_npv_test) -\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)),\n",
        "                                                                   np.mean (mean_npv_test) +\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)))\n",
        "                                                                  )\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XGBoost (Table 2)\n"
      ],
      "metadata": {
        "id": "uDavw-UTDIoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(rm)\n",
        "border = 0.41\n",
        "\n",
        "########### XGBoost\n",
        "lr=0.03\n",
        "m_d=2\n",
        "n_e=200\n",
        "spw=3\n",
        "child_weight=1\n",
        "sub=0.7\n",
        "max_step=1\n",
        "gam=2\n",
        "method ='exact'\n",
        "boost= 'gbtree'\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "\n",
        "for j in range(100):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "    # We set aside 20% for final testing\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data[features],model_data[y_name],\n",
        "                                                          train_size=0.8,\n",
        "                                                          stratify=model_data[y_name],\n",
        "                                                          random_state = rm )\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x_validate = np.array(x_validate)\n",
        "    y_validate = utils.to_categorical(y_validate)\n",
        "\n",
        "    roc_auc_test=[]\n",
        "    sen_test=[]\n",
        "    spec_test=[]\n",
        "    matr_test=[]\n",
        "    f1_test=[]\n",
        "    ppv_test=[]\n",
        "    npv_test=[]\n",
        "    threshold_test=[]\n",
        "    skf = StratifiedKFold(n_splits=n_splits )\n",
        "\n",
        "    # training and cross-validation\n",
        "    for i, (train_index, test_index) in enumerate(skf.split(x, y[:,1])):\n",
        "\n",
        "        x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "        y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "        model = xgb.XGBClassifier(learning_rate=lr,  eval_metric = \"auc\",\n",
        "                                      scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                                      verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                                      tree_method =method, max_delta_step=max_step, gamma=gam,\n",
        "                                      min_child_weight=child_weight,\n",
        "                                      subsample=sub, colsample_bylevel=1,\n",
        "                                      n_jobs=-1, use_label_encoder=False\n",
        "                                     )\n",
        "\n",
        "        np.random.seed(rm)\n",
        "        model.fit(x_train, y_train[:,1])\n",
        "        y_pred_log=model.predict_proba(x_test)\n",
        "        new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "        new_y = np.array(new_y)\n",
        "        cMatrix = confusion_matrix(y_test[:,1].astype(\"int\"), new_y)\n",
        "        sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "        specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "        sen_test.append(sensivity)\n",
        "        spec_test.append(specifity)\n",
        "        fpr,tpr,thresholds = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_test.append(roc_auc)\n",
        "        f1=f1_score(y_test[:,1], new_y)\n",
        "        f1_test.append(f1)\n",
        "        ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "        npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "        ppv_test.append(ppv)\n",
        "        npv_test.append(npv)\n",
        "\n",
        "    mean_roc_auc_test.append(np.mean(roc_auc_test))\n",
        "    mean_sen_test.append(np.mean(sen_test))\n",
        "    mean_spec_test.append(np.mean(spec_test))\n",
        "    mean_f1_test.append(np.mean(f1_test))\n",
        "    mean_ppv_test.append(np.mean(ppv_test))\n",
        "    mean_npv_test.append(np.mean(npv_test))\n",
        "\n",
        "    model = xgb.XGBClassifier(learning_rate=lr,  eval_metric = \"auc\",\n",
        "                                      scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                                      verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                                      tree_method =method, max_delta_step=max_step, gamma=gam,\n",
        "                                      min_child_weight=child_weight,\n",
        "                                      subsample=sub, colsample_bylevel=1,\n",
        "                                      n_jobs=-1, use_label_encoder=False\n",
        "                                     )\n",
        "\n",
        "    np.random.seed(rm)\n",
        "    model.fit(x, y[:,1])\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "    cMatrix = confusion_matrix(y_validate[:,1].astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate[:,1], y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate[:,1], new_y)\n",
        "    ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Mean area under the ROC curve = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_roc_auc_test),\n",
        "                                                                       np.mean (mean_roc_auc_test) -\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test)) ,\n",
        "                                                                       np.mean (mean_roc_auc_test) +\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test) )\n",
        "                                                                             ))\n",
        "print('Mean Sensitivity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen_test),\n",
        "                                                                       np.mean (mean_sen_test) -\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test)) ,\n",
        "                                                                       np.mean (mean_sen_test) +\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test))\n",
        "                                                                               ))\n",
        "print('Mean Specificity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec_test),\n",
        "                                                                       np.mean (mean_spec_test) - 1.96 * np.std(mean_spec_test) /np.sqrt(len(mean_spec_test)),\n",
        "                                                                       np.mean (mean_spec_test) + 1.96 * np.std(mean_spec_test)/np.sqrt(len(mean_spec_test) ))\n",
        "                                                                            )\n",
        "print('Mean F1-score ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1_test),\n",
        "                                                                       np.mean (mean_f1_test) - 1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test)) ,\n",
        "                                                                       np.mean (mean_f1_test) +\n",
        "                                                                       1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean PPV ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv_test),\n",
        "                                                                       np.mean (mean_ppv_test) -\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test)) ,\n",
        "                                                                       np.mean (mean_ppv_test) +\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean NPV  ={:.4f} 95% [ {:.4f}, {:.4f}]'.format(np.mean (mean_npv_test),\n",
        "                                                                   np.mean (mean_npv_test) -\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)),\n",
        "                                                                   np.mean (mean_npv_test) +\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)))\n",
        "                                                                  )\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )"
      ],
      "metadata": {
        "id": "tsYQIZpa0AK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Forest (Table 2)"
      ],
      "metadata": {
        "id": "9RUYrALsDLqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(rm)\n",
        "border = 0.22\n",
        "\n",
        "### Random Forest\n",
        "m_d1=8\n",
        "n_e1=110\n",
        "min_leaf = 0.01\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "\n",
        "for j in range(100):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "    # We set aside 20% for final testing\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data[features],model_data[y_name],\n",
        "                                                          train_size=0.8,\n",
        "                                                          stratify=model_data[y_name],\n",
        "                                                          random_state = rm )\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x_validate = np.array(x_validate)\n",
        "    y_validate = utils.to_categorical(y_validate)\n",
        "\n",
        "    roc_auc_test=[]\n",
        "    sen_test=[]\n",
        "    spec_test=[]\n",
        "    matr_test=[]\n",
        "    f1_test=[]\n",
        "    ppv_test=[]\n",
        "    npv_test=[]\n",
        "    threshold_test=[]\n",
        "    skf = StratifiedKFold(n_splits=n_splits )\n",
        "\n",
        "    # training and cross-validation\n",
        "    for i, (train_index, test_index) in enumerate(skf.split(x, y[:,1])):\n",
        "\n",
        "        x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "        y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "        model = RandomForestClassifier(random_state=rm, n_estimators=n_e1, max_depth=m_d1\n",
        "                                          ,min_samples_leaf = min_leaf\n",
        "                                          )\n",
        "\n",
        "        np.random.seed(rm)\n",
        "        model.fit(x_train, y_train[:,1])\n",
        "        y_pred_log=model.predict_proba(x_test)\n",
        "        new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "        new_y = np.array(new_y)\n",
        "        cMatrix = confusion_matrix(y_test[:,1].astype(\"int\"), new_y)\n",
        "        sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "        specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "        sen_test.append(sensivity)\n",
        "        spec_test.append(specifity)\n",
        "        fpr,tpr,thresholds = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_test.append(roc_auc)\n",
        "        f1=f1_score(y_test[:,1], new_y)\n",
        "        f1_test.append(f1)\n",
        "        ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "        npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "        ppv_test.append(ppv)\n",
        "        npv_test.append(npv)\n",
        "\n",
        "    mean_roc_auc_test.append(np.mean(roc_auc_test))\n",
        "    mean_sen_test.append(np.mean(sen_test))\n",
        "    mean_spec_test.append(np.mean(spec_test))\n",
        "    mean_f1_test.append(np.mean(f1_test))\n",
        "    mean_ppv_test.append(np.mean(ppv_test))\n",
        "    mean_npv_test.append(np.mean(npv_test))\n",
        "\n",
        "    model = RandomForestClassifier(random_state=rm, n_estimators=n_e1, max_depth=m_d1\n",
        "                                          ,min_samples_leaf = min_leaf\n",
        "                                          )\n",
        "\n",
        "    np.random.seed(rm)\n",
        "    model.fit(x, y[:,1])\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "    cMatrix = confusion_matrix(y_validate[:,1].astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate[:,1], y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate[:,1], new_y)\n",
        "    ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Mean area under the ROC curve = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_roc_auc_test),\n",
        "                                                                       np.mean (mean_roc_auc_test) -\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test)) ,\n",
        "                                                                       np.mean (mean_roc_auc_test) +\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test) )\n",
        "                                                                             ))\n",
        "print('Mean Sensitivity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen_test),\n",
        "                                                                       np.mean (mean_sen_test) -\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test)) ,\n",
        "                                                                       np.mean (mean_sen_test) +\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test))\n",
        "                                                                               ))\n",
        "print('Mean Specificity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec_test),\n",
        "                                                                       np.mean (mean_spec_test) - 1.96 * np.std(mean_spec_test) /np.sqrt(len(mean_spec_test)),\n",
        "                                                                       np.mean (mean_spec_test) + 1.96 * np.std(mean_spec_test)/np.sqrt(len(mean_spec_test) ))\n",
        "                                                                            )\n",
        "print('Mean F1-score ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1_test),\n",
        "                                                                       np.mean (mean_f1_test) - 1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test)) ,\n",
        "                                                                       np.mean (mean_f1_test) +\n",
        "                                                                       1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean PPV ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv_test),\n",
        "                                                                       np.mean (mean_ppv_test) -\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test)) ,\n",
        "                                                                       np.mean (mean_ppv_test) +\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean NPV  ={:.4f} 95% [ {:.4f}, {:.4f}]'.format(np.mean (mean_npv_test),\n",
        "                                                                   np.mean (mean_npv_test) -\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)),\n",
        "                                                                   np.mean (mean_npv_test) +\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)))\n",
        "                                                                  )\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )"
      ],
      "metadata": {
        "id": "qvF_PXinCihS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dichotomization of continuous predictors (Table 3)"
      ],
      "metadata": {
        "id": "x3K6ILpvDQVm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_DutcnAdhmj"
      },
      "source": [
        "\n",
        "### Search for the cutoff threshold - Min(p-value) (Table 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6CHX77Ldhmj"
      },
      "outputs": [],
      "source": [
        "features =[ {\"name\":'Age, years', \"sign\":\">\" },\n",
        "            {\"name\":'LV ESD, cm', \"sign\":\">\" },\n",
        "            {\"name\":'RAD, cm', \"sign\":\"<\" },\n",
        "            {\"name\":'QRS, ms\\n', \"sign\":\">\" },\n",
        "            {\"name\":'QT, ms\\n', \"sign\":\">\" },\n",
        "            {\"name\":'RR, ms\\n', \"sign\":\">\" },\n",
        "            {\"name\":'PQ, ms\\n', \"sign\":\">\" },\n",
        "            {\"name\":'P, ms', \"sign\":\">\" },\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "\n",
        "name1='isParameter'\n",
        "for feature in features:\n",
        "  name = feature[\"name\"]\n",
        "  sign = feature[\"sign\"]\n",
        "  print( \"Feature: \" + name )\n",
        "\n",
        "  pmin = 1\n",
        "  #### min (p-value) & max (ОШ)\n",
        "  d=data.loc[:,(name, y_name)].dropna()\n",
        "  d[name1]=None\n",
        "\n",
        "  x0=d[name].min()\n",
        "  x1=d[name].max()\n",
        "\n",
        "  delta = (x1-x0)/100\n",
        "\n",
        "  if sign == '>':\n",
        "      xcurrent=x0+delta\n",
        "      xp=x0\n",
        "  else:\n",
        "      xcurrent=x1-delta\n",
        "      xp=x1\n",
        "\n",
        "  yPV=[]\n",
        "  xPV=[]\n",
        "  ##########  Minimizing  P-value\n",
        "  while (xcurrent < x1) & (xcurrent > x0):\n",
        "      d[name1]=None\n",
        "      if sign == '>':\n",
        "          d.loc[(d[name] > xcurrent ),(name1)]= 1\n",
        "          d.loc[(d[name] <= xcurrent ),(name1)]= 0\n",
        "      else:\n",
        "          d.loc[(d[name] < xcurrent ),(name1)]= 1\n",
        "          d.loc[(d[name] >= xcurrent ),(name1)]= 0\n",
        "\n",
        "      ct=pd.crosstab(d[y_name], d[(name1)])\n",
        "      ### Chi-square test for p-value\n",
        "      pvalue=scipy.stats.chi2_contingency(ct)[1]\n",
        "      if (pvalue < pmin):\n",
        "          pmin=pvalue\n",
        "          xp=xcurrent\n",
        "\n",
        "      if sign == '>':\n",
        "          xcurrent += delta\n",
        "      else:\n",
        "          xcurrent -= delta\n",
        "\n",
        "      xPV.append(xcurrent)\n",
        "      yPV.append(pvalue)\n",
        "\n",
        "  ##########   P-value\n",
        "  print(f'Cutoff threshold = {xp}  Min(p-value)= {pmin} ' )\n",
        "\n",
        "  ## Calculating additional metrics for the threshold with the minimum AUC\n",
        "  if sign == '>':\n",
        "      d.loc[(d[name] > xp ),(name1)]= 1\n",
        "      d.loc[(d[name] <= xp ),(name1)]= 0\n",
        "  else:\n",
        "      d.loc[(d[name] < xp ),(name1)]= 1\n",
        "      d.loc[(d[name] >= xp ),(name1)]= 0\n",
        "\n",
        "  table = sm.stats.Table2x2(pd.crosstab(d[y_name], d[(name1)]), shift_zeros=False)\n",
        "  print(f'OdssRation= {table.oddsratio}, 95%CI = {table.oddsratio_confint()} \\np-value OR= {table.oddsratio_pvalue()} ')\n",
        "\n",
        "\n",
        "  ################## Сalculating AUC\n",
        "  if sign == '>':\n",
        "      data.loc[(data[name] > xp ),(name1)]= 1\n",
        "      data.loc[(data[name] <= xp ),(name1)]= 0\n",
        "  else:\n",
        "      data.loc[(data[name] < xp ),(name1)]= 1\n",
        "      data.loc[(data[name] >= xp ),(name1)]= 0\n",
        "\n",
        "  columns = [(name1)]\n",
        "  columns.append(y_name)\n",
        "  model_data = data[columns]\n",
        "  model_data = model_data.dropna()\n",
        "  columns.remove(y_name)\n",
        "\n",
        "  x = np.array(model_data[columns])  #Select only significant columns\n",
        "  y1 = np.array(model_data[y_name].astype('int')) ##Column of class labels\n",
        "  y = utils.to_categorical(y1)\n",
        "\n",
        "  n_splits=10\n",
        "  kf = StratifiedKFold(n_splits=n_splits )\n",
        "  roc_auc_max_log=0\n",
        "  roc_auc_test=[]\n",
        "  for train_index, test_index in kf.split(x,y[:,1]):\n",
        "\n",
        "      x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "      y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "      ########### Logistic regression\n",
        "      model = LogisticRegression(solver = 'lbfgs',  max_iter = 10000, C = 1,  penalty='l2')\n",
        "      model.fit(x_train, y_train[:,1])\n",
        "      y_pred_log=model.predict_proba(x_test)\n",
        "      fpr,tpr,_ = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "      roc_auc = auc(fpr, tpr)\n",
        "      roc_auc_test.append(roc_auc)\n",
        "\n",
        "  print('AUC (p-value) = %.4f' % np.mean (roc_auc_test) )\n",
        "  model = LogisticRegression(solver = 'lbfgs',  max_iter = 10000, C = 1,  penalty='l2')\n",
        "  model.fit(x, y[:,1])\n",
        "  print('Coef(p-value)', model.coef_[0])\n",
        "  print('='*60 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1JXA0AUdhmj"
      },
      "source": [
        "### Search for the cutoff threshold - Max(AUC) (Table 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqvOj1e9dhmk"
      },
      "outputs": [],
      "source": [
        "features =[ {\"name\":'Age, years', \"sign\":\">\" },\n",
        "            {\"name\":'LV ESD, cm', \"sign\":\">\" },\n",
        "            {\"name\":'RAD, cm', \"sign\":\"<\" },\n",
        "            {\"name\":'QRS, ms\\n', \"sign\":\">\" },\n",
        "            {\"name\":'QT, ms\\n', \"sign\":\">\" },\n",
        "            {\"name\":'RR, ms\\n', \"sign\":\">\" },\n",
        "            {\"name\":'PQ, ms\\n', \"sign\":\">\" },\n",
        "            {\"name\":'P, ms', \"sign\":\">\" },\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "\n",
        "name1='isParameter'\n",
        "for feature in features:\n",
        "  name = feature[\"name\"]\n",
        "  sign = feature[\"sign\"]\n",
        "  print( \"Feature: \" + name )\n",
        "\n",
        "  d=data.loc[:,(name,y_name)].dropna()\n",
        "  d[name1]=None\n",
        "\n",
        "  x0=d[name].min()\n",
        "  x1=d[name].max()\n",
        "  delta = (x1-x0)/100\n",
        "\n",
        "  if sign == '>':\n",
        "      xcurrent=x0+delta\n",
        "      xauc=x0\n",
        "  else:\n",
        "      xcurrent=x1-delta\n",
        "      xauc=x1\n",
        "\n",
        "  aucmax=0\n",
        "  pvaluemin=1\n",
        "\n",
        "  xAUC=[]\n",
        "  yAUC=[]\n",
        "  ##########  Мax(AUC)\n",
        "  while (xcurrent < x1) & (xcurrent > x0):\n",
        "      data.loc[:,(name1)]=None\n",
        "\n",
        "      if sign == '>':\n",
        "          data.loc[(data[name] > xcurrent ),(name1)]= 1\n",
        "          data.loc[(data[name] <= xcurrent ),(name1)]= 0\n",
        "      else:\n",
        "          data.loc[(data[name] < xcurrent ),(name1)]= 1\n",
        "          data.loc[(data[name] >= xcurrent ),(name1)]= 0\n",
        "\n",
        "      columns = [(name1)]\n",
        "      columns.append(y_name)\n",
        "      model_data = data[columns]\n",
        "      model_data = model_data.dropna()\n",
        "      columns.remove(y_name)\n",
        "\n",
        "      x = np.array(model_data[columns])\n",
        "      y1 = np.array(model_data[y_name].astype('int'))\n",
        "      y = utils.to_categorical(y1)\n",
        "\n",
        "      n_splits=7\n",
        "      kf = StratifiedKFold(n_splits=n_splits )\n",
        "      roc_auc_max_log=0\n",
        "      roc_auc_test=[]\n",
        "      for train_index, test_index in kf.split(x,y[:,1]):\n",
        "\n",
        "          x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "          y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "          ########### Logistic regression\n",
        "          model = LogisticRegression(solver = 'lbfgs',  max_iter = 10000, C = 300\n",
        "                                    )\n",
        "          model.fit(x_train, y_train[:,1])\n",
        "          y_pred_log=model.predict_proba(x_test)\n",
        "          fpr,tpr,_ = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "          roc_auc = auc(fpr, tpr)\n",
        "          roc_auc_test.append(roc_auc)\n",
        "      if ( (aucmax < np.mean (roc_auc_test)) ):\n",
        "          aucmax=np.mean (roc_auc_test)\n",
        "          xauc=xcurrent\n",
        "\n",
        "      if sign == '>':\n",
        "          xcurrent += delta\n",
        "      else:\n",
        "          xcurrent -= delta\n",
        "\n",
        "      xAUC.append(xcurrent)\n",
        "      yAUC.append(np.mean (roc_auc_test))\n",
        "          ##########   MAX(AUC)\n",
        "  print(f'Cutoff threshold = {xauc}  Max(AUC)= {aucmax} Min={x0} Max={x1} ')\n",
        "\n",
        "  ##Calculate additional metrics for the threshold with the maximum AUC\n",
        "  if sign == '>':\n",
        "          data.loc[(data[name] > xauc ),(name1)]= 1\n",
        "          data.loc[(data[name] <= xauc ),(name1)]= 0\n",
        "  else:\n",
        "          data.loc[(data[name] < xauc ),(name1)]= 1\n",
        "          data.loc[(data[name] >= xauc ),(name1)]= 0\n",
        "\n",
        "  ###Chi-square test for p-value\n",
        "  pvalue=scipy.stats.chi2_contingency(pd.crosstab(data[y_name], data[(name1)]))[1]\n",
        "  print(f'Pvalue chi-square test = {pvalue}')\n",
        "  ### Odds ratio\n",
        "\n",
        "  table = sm.stats.Table2x2(pd.crosstab(data[y_name], data[(name1)]), shift_zeros=False)\n",
        "  print(f'OdssRation= {table.oddsratio}, 95%CI = {table.oddsratio_confint()} \\np-value OR= {table.oddsratio_pvalue()} ')\n",
        "\n",
        "  print('='*60 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search for the cutoff threshold - Centroid (Table 3)\n"
      ],
      "metadata": {
        "id": "nKLqjgdDQiNw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSw_eIZRdhmk"
      },
      "outputs": [],
      "source": [
        "features =[ {\"name\":'Age, years', \"sign\":\">\" },\n",
        "            {\"name\":'LV ESD, cm', \"sign\":\">\" },\n",
        "            {\"name\":'RAD, cm', \"sign\":\"<\" },\n",
        "            {\"name\":'QRS, ms\\n', \"sign\":\">\" },\n",
        "            {\"name\":'QT, ms\\n', \"sign\":\">\" },\n",
        "            {\"name\":'RR, ms\\n', \"sign\":\">\" },\n",
        "            {\"name\":'PQ, ms\\n', \"sign\":\">\" },\n",
        "            {\"name\":'P, ms', \"sign\":\">\" },\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "\n",
        "name1='isParameter'\n",
        "for feature in features:\n",
        "  name = feature[\"name\"]\n",
        "  sign = feature[\"sign\"]\n",
        "  print( \"Feature: \" + name )\n",
        "\n",
        "  d=data.loc[:,(name,y_name)].dropna()\n",
        "  d[name1]=None\n",
        "\n",
        "  a = d.groupby([y_name])[(name)].describe()\n",
        "  mean1 = a.iloc[1][\"50%\"]\n",
        "  mean0 = a.iloc[0][\"50%\"]\n",
        "  xcenter=(mean1 + mean0)/2\n",
        "  print('Порог=',xcenter)\n",
        "\n",
        "  if sign == '>':\n",
        "          d.loc[(d[name] > xcenter ),(name1)]= 1\n",
        "          d.loc[(d[name] <= xcenter ),(name1)]= 0\n",
        "  else:\n",
        "          d.loc[(d[name] < xcenter ),(name1)]= 1\n",
        "          d.loc[(d[name] >= xcenter ),(name1)]= 0\n",
        "  ### Chi-quadrant test\n",
        "  pvalue=scipy.stats.chi2_contingency(pd.crosstab(d[y_name], d[(name1)]))[1]\n",
        "  print(f'pvalue хи-квадрат теста = {pvalue}')\n",
        "  ### Odds ratio\n",
        "\n",
        "  table = sm.stats.Table2x2(pd.crosstab(d[y_name], d[(name1)]), shift_zeros=False)\n",
        "  print(f'OdssRation= {table.oddsratio}, 95%CI = {table.oddsratio_confint()} \\np-value OR= {table.oddsratio_pvalue()} ')\n",
        "\n",
        "  ################## Calculating AUC\n",
        "  if sign == '>':\n",
        "      data.loc[(data[name] > xcenter ),(name1)]= 1\n",
        "      data.loc[(data[name] <= xcenter ),(name1)]= 0\n",
        "  else:\n",
        "      data.loc[(data[name] < xcenter ),(name1)]= 1\n",
        "      data.loc[(data[name] >= xcenter ),(name1)]= 0\n",
        "\n",
        "  columns = [(name1)]\n",
        "  columns.append(y_name)\n",
        "  model_data = data[columns]\n",
        "  model_data = model_data.dropna()\n",
        "  columns.remove(y_name)\n",
        "\n",
        "  x = np.array(model_data[columns])\n",
        "  y1 = np.array(model_data[y_name].astype('int'))\n",
        "  y = utils.to_categorical(y1)\n",
        "\n",
        "  n_splits=10\n",
        "  kf = StratifiedKFold(n_splits=n_splits )\n",
        "  roc_auc_max_log=0\n",
        "  roc_auc_test=[]\n",
        "  for train_index, test_index in kf.split(x,y[:,1]):\n",
        "\n",
        "      x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "      y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "      ########### Logistic regression\n",
        "      model = LogisticRegression(solver = 'lbfgs',  max_iter = 10000, C = 1,  penalty='l2')\n",
        "      model.fit(x_train, y_train[:,1])\n",
        "      y_pred_log=model.predict_proba(x_test)\n",
        "      fpr,tpr,_ = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "      roc_auc = auc(fpr, tpr)\n",
        "      roc_auc_test.append(roc_auc)\n",
        "\n",
        "  print('AUC = %.4f' % np.mean (roc_auc_test) )\n",
        "\n",
        "  print('='*60 + \"\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search for the cutoff threshold - SHAP (Table 3)"
      ],
      "metadata": {
        "id": "Hurgt59CU0oJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkCY72N7dhmo"
      },
      "outputs": [],
      "source": [
        "model = xgb.XGBClassifier( learning_rate=lr,  eval_metric = \"auc\",\n",
        "                              scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                              verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                              tree_method =method, max_delta_step=max_step,\n",
        "                              gamma=gam, min_child_weight=child_weight,\n",
        "                              subsample=sub, colsample_bylevel=1,\n",
        "                                 n_jobs=-1 , use_label_encoder=False\n",
        "                             )\n",
        "\n",
        "features =[ 'Age, years',  'RAD, cm' , 'LV ESD, cm',\n",
        "            'QT, ms\\n', 'QRS, ms\\n', 'PQ, ms\\n',  'RR, ms\\n' , 'P, ms' ,\n",
        "            'Tricuspid regurgitation' ,\n",
        "            ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features]\n",
        "model_data = model_data.dropna()\n",
        "features.remove(y_name)\n",
        "model_data_copy=model_data.copy()\n",
        "model_data_copy=model_data_copy[features]\n",
        "\n",
        "x_all = np.array(model_data[features])\n",
        "y1 = np.array(model_data[y_name].astype('int'))\n",
        "y_all = utils.to_categorical(y1)\n",
        "\n",
        "model.fit(x_all, y_all[:,1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qjw-gK9cdhmo"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "plt.rcParams.update({'font.size': 10})\n",
        "\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(x_all)\n",
        "shap_values_df = pd.DataFrame(shap_values )\n",
        "\n",
        "\n",
        "plt.figure(figsize=[11,26],dpi = 100)\n",
        "\n",
        "#####Age\n",
        "plt.subplot(9, 2, 1)\n",
        "pp = pd.DataFrame({'X': np.array(model_data[features[0]])\n",
        "                   , 'shap':np.array(shap_values_df[0])\n",
        "                  })\n",
        "m=np.max(pp['shap'])\n",
        "xx=min_age_above_0_2 = pp.loc[pp['shap'] > m/3, 'X'].min()\n",
        "yy=np.min(pp['shap'])\n",
        "print(xx, yy, m)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.5)\n",
        "plt.minorticks_on()\n",
        "plt.grid()\n",
        "plt.scatter(  model_data[features[0]],shap_values_df[0], s = 2  )\n",
        "plt.xlim(( np.min(model_data[features[0]])-np.min(model_data[features[0]])/20,\n",
        "          np.max(model_data[features[0]])+np.max(model_data[features[0]])/20))\n",
        "plt.xlabel(features[0])\n",
        "\n",
        "\n",
        "plt.ylabel('SHAP value')\n",
        "plt.axvline(x=xx, color='blue', linestyle='--')\n",
        "plt.axhline(y=0, color='black')\n",
        "plt.axhline(y=m/2, color='black', linestyle='--')\n",
        "plt.text(xx+2, yy, f'{int(xx):}', color='blue', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "#####  RAD\n",
        "plt.subplot(9, 2, 2)\n",
        "pp = pd.DataFrame({'X': np.array(model_data[features[1]])\n",
        "                   , 'shap':np.array(shap_values_df[1])\n",
        "                  })\n",
        "m=np.max(pp['shap'])\n",
        "\n",
        "xx=min_age_above_0_2 = pp.loc[pp['shap'] > m/10, 'X'].min()\n",
        "yy=np.min(pp['shap'])\n",
        "print(xx, yy, m)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.5)\n",
        "plt.minorticks_on()\n",
        "plt.grid()\n",
        "plt.scatter(  model_data[features[1]],shap_values_df[1], s = 2  )\n",
        "plt.xlim([ np.min(model_data[features[1]])-np.min(model_data[features[1]])/20,\n",
        "          np.max(model_data[features[1]])+np.max(model_data[features[1]])/20])\n",
        "plt.xlabel(features[1])\n",
        "\n",
        "\n",
        "plt.ylabel('SHAP value')\n",
        "plt.axvline(x=xx, color='blue', linestyle='--')\n",
        "xx1=5.3\n",
        "plt.axvline(x=xx1, color='red', linestyle='--')\n",
        "\n",
        "plt.axhline(y=0, color='black')\n",
        "plt.axhline(y=m/2, color='black', linestyle='--')\n",
        "plt.text(xx+0.2, yy, f'{xx:.1f}', color='blue', ha='center', va='bottom', fontsize=10)\n",
        "plt.text(xx1+0.2, yy, f'{xx1:.1f}', color='red', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "#####  LV ESD\n",
        "plt.subplot(9, 2, 3)\n",
        "pp = pd.DataFrame({'X': np.array(model_data[features[2]])\n",
        "                   , 'shap':np.array(shap_values_df[2])\n",
        "                  })\n",
        "m=np.max(pp['shap'])\n",
        "\n",
        "xx=min_age_above_0_2 = pp.loc[pp['shap'] > m/3, 'X'].min()\n",
        "yy=np.min(pp['shap'])\n",
        "print(xx, yy, m)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.5)\n",
        "plt.minorticks_on()\n",
        "plt.grid()\n",
        "plt.scatter(  model_data[features[2]],shap_values_df[2], s = 2  )\n",
        "plt.xlim([ np.min(model_data[features[2]])-np.min(model_data[features[2]])/20,\n",
        "          np.max(model_data[features[2]])+np.max(model_data[features[2]])/20])\n",
        "plt.xlabel(features[2])\n",
        "\n",
        "plt.ylabel('SHAP value')\n",
        "plt.axvline(x=xx, color='blue', linestyle='--')\n",
        "xx1=4.1\n",
        "plt.axvline(x=xx1, color='red', linestyle='--')\n",
        "xx2=5\n",
        "plt.axvline(x=xx2, color='blue', linestyle='--')\n",
        "plt.axhline(y=0, color='black')\n",
        "plt.axhline(y=m/3, color='black', linestyle='--')\n",
        "plt.text(xx+0.2, yy, f'{xx:.1f}', color='blue', ha='center', va='bottom', fontsize=10)\n",
        "plt.text(xx1+0.2, yy, f'{xx1:.1f}', color='red', ha='center', va='bottom', fontsize=10)\n",
        "plt.text(xx1+0.2, yy, f'{xx1:.1f}', color='red', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "#####  QT, ms\n",
        "plt.subplot(9, 2, 4)\n",
        "pp = pd.DataFrame({'X': np.array(model_data[features[3]])\n",
        "                   , 'shap':np.array(shap_values_df[3])\n",
        "                  })\n",
        "m=np.max(pp['shap'])\n",
        "\n",
        "xx=390\n",
        "yy=np.min(pp['shap'])\n",
        "print(xx, yy, m)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.5)\n",
        "plt.minorticks_on()\n",
        "plt.grid()\n",
        "plt.scatter(  model_data[features[3]],shap_values_df[3], s = 2  )\n",
        "plt.xlim([ np.min(model_data[features[3]])-np.min(model_data[features[3]])/20,\n",
        "          np.max(model_data[features[3]])+np.max(model_data[features[3]])/20])\n",
        "plt.xlabel(features[3])\n",
        "plt.ylabel('SHAP value')\n",
        "plt.axvline(x=xx, color='blue', linestyle='--')\n",
        "plt.axhline(y=0, color='black')\n",
        "plt.axhline(y=m/3, color='black', linestyle='--')\n",
        "plt.text(xx+30, yy, f'{xx:.1f}', color='blue', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "#### QRS, ms\n",
        "plt.subplot(9, 2, 5)\n",
        "pp = pd.DataFrame({'X': np.array(model_data[features[4]])\n",
        "                   , 'shap':np.array(shap_values_df[4])\n",
        "                  })\n",
        "m=np.max(pp['shap'])\n",
        "xx=min_age_above_0_2 = pp.loc[pp['shap'] > m/3, 'X'].max()\n",
        "yy=np.min(pp['shap'])\n",
        "print(xx, yy, m)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.5)\n",
        "plt.minorticks_on()\n",
        "plt.grid()\n",
        "plt.scatter(  model_data[features[4]],shap_values_df[4], s = 2  )\n",
        "plt.xlim([ np.min(model_data[features[4]])-np.min(model_data[features[4]])/20,\n",
        "          np.max(model_data[features[4]])+np.max(model_data[features[4]])/20])\n",
        "plt.xlabel(features[4])\n",
        "plt.ylabel('SHAP value')\n",
        "plt.axvline(x=xx, color='blue', linestyle='--')\n",
        "plt.axhline(y=0, color='black')\n",
        "plt.axhline(y=m/3, color='black', linestyle='--')\n",
        "plt.text(xx+5, yy, f'{int(xx):}', color='blue', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "#### PQ, ms\n",
        "plt.subplot(9, 2, 6)\n",
        "pp = pd.DataFrame({'X': np.array(model_data[features[5]])\n",
        "                   , 'shap':np.array(shap_values_df[5])\n",
        "                  })\n",
        "m=np.max(pp['shap'])\n",
        "xx=min_age_above_0_2 = pp.loc[pp['shap'] > m/3, 'X'].min()\n",
        "yy=np.min(pp['shap'])\n",
        "print(xx, yy, m)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.5)\n",
        "plt.minorticks_on()\n",
        "plt.grid()\n",
        "plt.scatter(  model_data[features[5]],shap_values_df[5], s = 2  )\n",
        "plt.xlim([ np.min(model_data[features[5]])-np.min(model_data[features[5]])/20,\n",
        "          np.max(model_data[features[5]])+np.max(model_data[features[5]])/20])\n",
        "plt.xlabel(features[5])\n",
        "plt.ylabel('SHAP value')\n",
        "plt.axvline(x=xx, color='blue', linestyle='--')\n",
        "xx1=210\n",
        "plt.axvline(x=xx1, color='red', linestyle='--')\n",
        "plt.axhline(y=0, color='black')\n",
        "plt.axhline(y=m/3, color='black', linestyle='--')\n",
        "plt.text(xx+15, yy, f'{int(xx):}', color='blue', ha='center', va='bottom', fontsize=10)\n",
        "plt.text(xx1+15, yy, f'{int(xx1):}', color='red', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "#### RR, ms\n",
        "plt.subplot(9, 2, 7)\n",
        "pp = pd.DataFrame({'X': np.array(model_data[features[6]])\n",
        "                   , 'shap':np.array(shap_values_df[6])\n",
        "                  })\n",
        "m=np.max(pp['shap'])\n",
        "\n",
        "xx=min_age_above_0_2 = pp.loc[pp['shap'] > m/3, 'X'].min()\n",
        "yy=np.min(pp['shap'])\n",
        "print(xx, yy, m)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.5)\n",
        "plt.minorticks_on()\n",
        "plt.grid()\n",
        "plt.scatter(  model_data[features[6]],shap_values_df[6], s = 2  )\n",
        "plt.xlim([ np.min(model_data[features[6]])-np.min(model_data[features[6]])/20,\n",
        "          np.max(model_data[features[6]])+np.max(model_data[features[6]])/20])\n",
        "plt.xlabel(features[6])\n",
        "plt.ylabel('SHAP value')\n",
        "plt.axvline(x=xx, color='blue', linestyle='--')\n",
        "xx1=750\n",
        "plt.axvline(x=xx1, color='red', linestyle='--')\n",
        "xx2=880\n",
        "plt.axvline(x=xx2, color='blue', linestyle='--')\n",
        "xx3=1000\n",
        "plt.axvline(x=xx3, color='red', linestyle='--')\n",
        "xx4=1100\n",
        "plt.axvline(x=xx4, color='blue', linestyle='--')\n",
        "plt.axhline(y=0, color='black')\n",
        "plt.axhline(y=m/3, color='black', linestyle='--')\n",
        "plt.text(xx-60, yy, f'{int(xx):}', color='blue', ha='center', va='bottom', fontsize=10)\n",
        "plt.text(xx1+60, yy, f'{int(xx1):}', color='red', ha='center', va='bottom', fontsize=10)\n",
        "plt.text(xx2+60, yy, f'{int(xx2):}', color='blue', ha='center', va='bottom', fontsize=10)\n",
        "plt.text(xx3+60, yy, f'{int(xx3):}', color='red', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "#### P, ms\n",
        "plt.subplot(9, 2, 8)\n",
        "pp = pd.DataFrame({'X': np.array(model_data[features[7]])\n",
        "                   , 'shap':np.array(shap_values_df[7])\n",
        "                  })\n",
        "m=np.max(pp['shap'])\n",
        "xx=min_age_above_0_2 = pp.loc[pp['shap'] > m/3, 'X'].min()\n",
        "yy=np.min(pp['shap'])\n",
        "print(xx, yy, m)\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.5)\n",
        "plt.minorticks_on()\n",
        "plt.grid()\n",
        "plt.scatter(  model_data[features[7]],shap_values_df[7], s = 2  )\n",
        "plt.xlim([ np.min(model_data[features[7]])-np.min(model_data[features[7]])/20,\n",
        "          np.max(model_data[features[7]])+np.max(model_data[features[7]])/20])\n",
        "plt.xlabel(features[7])\n",
        "plt.ylabel('SHAP value')\n",
        "plt.axvline(x=xx, color='blue', linestyle='--')\n",
        "plt.axhline(y=0, color='black')\n",
        "plt.axhline(y=m/3, color='black', linestyle='--')\n",
        "plt.text(xx+5, yy, f'{int(xx):}', color='blue', ha='center', va='bottom', fontsize=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Development of models based on categorical variables (Table 4)"
      ],
      "metadata": {
        "id": "63W79_2uypTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Minimum p-value (Table 4)"
      ],
      "metadata": {
        "id": "bgg50OPD1Spw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='cat Age'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=60 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 60 ),(name)]= 0\n",
        "\n",
        "name='cat RAD'\n",
        "data[name]=None\n",
        "data.loc[(data['RAD, cm'] >= 4.17 ) , (name)]= 1\n",
        "data.loc[(data['RAD, cm'] < 4.17 ) , (name)]= 0\n",
        "\n",
        "name='cat LV ESD'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 3), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 3 ),(name)]= 0\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[(data['QRS, ms\\n'] < 81),(name)]= 1\n",
        "data.loc[(data['QRS, ms\\n'] >= 81 ),(name)]= 0\n",
        "\n",
        "name='cat QT'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 420),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 420 ),(name)]= 0\n",
        "\n",
        "name='cat PQ'\n",
        "data[name]=None\n",
        "data.loc[(data['PQ, ms\\n'] >= 163), (name)]= 1\n",
        "data.loc[(data['PQ, ms\\n'] < 163 ), (name)]= 0\n",
        "\n",
        "name='cat RR'\n",
        "data[name]=None\n",
        "data.loc[ (data['RR, ms\\n'] >= 882), (name)]= 1\n",
        "data.loc[ (data['RR, ms\\n'] < 882), (name)]= 0\n",
        "\n",
        "name='cat P'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 120),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 120 ),(name)]= 0\n",
        "\n",
        "\n",
        "features =[ 'cat Age',  'cat RAD' , 'Tricuspid regurgitation' ,  'cat QRS' , 'cat QT', 'cat RR' ,'cat PQ', 'cat P' ,  'cat LV ESD'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.2\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10\n",
        "\n",
        "np.random.seed(rm)\n",
        "\n",
        "########### LogisticRegression\n",
        "max_iter = 100\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "\n",
        "for j in range(100):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "    # We set aside 20% for final testing\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data[features],model_data[y_name],\n",
        "                                                          train_size=0.8,\n",
        "                                                          stratify=model_data[y_name],\n",
        "                                                          random_state = rm )\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x_validate = np.array(x_validate)\n",
        "    y_validate = utils.to_categorical(y_validate)\n",
        "\n",
        "    roc_auc_test=[]\n",
        "    sen_test=[]\n",
        "    spec_test=[]\n",
        "    matr_test=[]\n",
        "    f1_test=[]\n",
        "    ppv_test=[]\n",
        "    npv_test=[]\n",
        "    threshold_test=[]\n",
        "    skf = StratifiedKFold(n_splits=n_splits )\n",
        "\n",
        "    # training and cross-validation\n",
        "    for i, (train_index, test_index) in enumerate(skf.split(x, y[:,1])):\n",
        "\n",
        "        x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "        y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "        model = LogisticRegression( max_iter=max_iter )\n",
        "\n",
        "\n",
        "        np.random.seed(rm)\n",
        "        model.fit(x_train, y_train[:,1])\n",
        "        y_pred_log=model.predict_proba(x_test)\n",
        "        new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "        new_y = np.array(new_y)\n",
        "        cMatrix = confusion_matrix(y_test[:,1].astype(\"int\"), new_y)\n",
        "        sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "        specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "        sen_test.append(sensivity)\n",
        "        spec_test.append(specifity)\n",
        "        fpr,tpr,thresholds = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_test.append(roc_auc)\n",
        "        f1=f1_score(y_test[:,1], new_y)\n",
        "        f1_test.append(f1)\n",
        "        ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "        npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "        ppv_test.append(ppv)\n",
        "        npv_test.append(npv)\n",
        "\n",
        "    mean_roc_auc_test.append(np.mean(roc_auc_test))\n",
        "    mean_sen_test.append(np.mean(sen_test))\n",
        "    mean_spec_test.append(np.mean(spec_test))\n",
        "    mean_f1_test.append(np.mean(f1_test))\n",
        "    mean_ppv_test.append(np.mean(ppv_test))\n",
        "    mean_npv_test.append(np.mean(npv_test))\n",
        "\n",
        "    model = LogisticRegression( max_iter=max_iter )\n",
        "\n",
        "    np.random.seed(rm)\n",
        "    model.fit(x, y[:,1])\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "    cMatrix = confusion_matrix(y_validate[:,1].astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate[:,1], y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate[:,1], new_y)\n",
        "    ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Mean area under the ROC curve = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_roc_auc_test),\n",
        "                                                                       np.mean (mean_roc_auc_test) -\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test)) ,\n",
        "                                                                       np.mean (mean_roc_auc_test) +\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test) )\n",
        "                                                                             ))\n",
        "print('Mean Sensitivity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen_test),\n",
        "                                                                       np.mean (mean_sen_test) -\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test)) ,\n",
        "                                                                       np.mean (mean_sen_test) +\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test))\n",
        "                                                                               ))\n",
        "print('Mean Specificity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec_test),\n",
        "                                                                       np.mean (mean_spec_test) - 1.96 * np.std(mean_spec_test) /np.sqrt(len(mean_spec_test)),\n",
        "                                                                       np.mean (mean_spec_test) + 1.96 * np.std(mean_spec_test)/np.sqrt(len(mean_spec_test) ))\n",
        "                                                                            )\n",
        "print('Mean F1-score ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1_test),\n",
        "                                                                       np.mean (mean_f1_test) - 1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test)) ,\n",
        "                                                                       np.mean (mean_f1_test) +\n",
        "                                                                       1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean PPV ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv_test),\n",
        "                                                                       np.mean (mean_ppv_test) -\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test)) ,\n",
        "                                                                       np.mean (mean_ppv_test) +\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean NPV  ={:.4f} 95% [ {:.4f}, {:.4f}]'.format(np.mean (mean_npv_test),\n",
        "                                                                   np.mean (mean_npv_test) -\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)),\n",
        "                                                                   np.mean (mean_npv_test) +\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)))\n",
        "                                                                  )\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )\n"
      ],
      "metadata": {
        "id": "8BMBXr06y1e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Maximum AUC (Table 4)"
      ],
      "metadata": {
        "id": "NFo4macxAOfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='cat Age'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=60 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 60 ),(name)]= 0\n",
        "\n",
        "name='cat RAD'\n",
        "data[name]=None\n",
        "data.loc[(data['RAD, cm'] >= 4.12 ) , (name)]= 1\n",
        "data.loc[(data['RAD, cm'] < 4.12 ) , (name)]= 0\n",
        "\n",
        "name='cat LV ESD'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 3), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 3 ),(name)]= 0\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[(data['QRS, ms\\n'] < 81),(name)]= 1\n",
        "data.loc[(data['QRS, ms\\n'] >= 81 ),(name)]= 0\n",
        "\n",
        "name='cat QT'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 382),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 382 ),(name)]= 0\n",
        "\n",
        "name='cat PQ'\n",
        "data[name]=None\n",
        "data.loc[(data['PQ, ms\\n'] >= 163 ), (name)]= 1\n",
        "data.loc[(data['PQ, ms\\n'] < 163 ), (name)]= 0\n",
        "\n",
        "name='cat RR'\n",
        "data[name]=None\n",
        "data.loc[ (data['RR, ms\\n'] >= 882), (name)]= 1\n",
        "data.loc[ (data['RR, ms\\n'] < 882), (name)]= 0\n",
        "\n",
        "name='cat P'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 100),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 100 ),(name)]= 0\n",
        "\n",
        "\n",
        "features =[ 'cat Age',  'cat RAD' , 'Tricuspid regurgitation' ,  'cat QRS' , 'cat QT', 'cat RR' ,'cat PQ', 'cat P' ,  'cat LV ESD'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.19\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10\n",
        "\n",
        "np.random.seed(rm)\n",
        "\n",
        "########### LogisticRegression\n",
        "max_iter = 100\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "\n",
        "for j in range(100):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "    # We set aside 20% for final testing\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data[features],model_data[y_name],\n",
        "                                                          train_size=0.8,\n",
        "                                                          stratify=model_data[y_name],\n",
        "                                                          random_state = rm )\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x_validate = np.array(x_validate)\n",
        "    y_validate = utils.to_categorical(y_validate)\n",
        "\n",
        "    roc_auc_test=[]\n",
        "    sen_test=[]\n",
        "    spec_test=[]\n",
        "    matr_test=[]\n",
        "    f1_test=[]\n",
        "    ppv_test=[]\n",
        "    npv_test=[]\n",
        "    threshold_test=[]\n",
        "    skf = StratifiedKFold(n_splits=n_splits )\n",
        "\n",
        "    # training and cross-validation\n",
        "    for i, (train_index, test_index) in enumerate(skf.split(x, y[:,1])):\n",
        "\n",
        "        x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "        y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "        model = LogisticRegression( max_iter=max_iter )\n",
        "\n",
        "        np.random.seed(rm)\n",
        "        model.fit(x_train, y_train[:,1])\n",
        "        y_pred_log=model.predict_proba(x_test)\n",
        "        new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "        new_y = np.array(new_y)\n",
        "        cMatrix = confusion_matrix(y_test[:,1].astype(\"int\"), new_y)\n",
        "        sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "        specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "        sen_test.append(sensivity)\n",
        "        spec_test.append(specifity)\n",
        "        fpr,tpr,thresholds = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_test.append(roc_auc)\n",
        "        f1=f1_score(y_test[:,1], new_y)\n",
        "        f1_test.append(f1)\n",
        "        ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "        npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "        ppv_test.append(ppv)\n",
        "        npv_test.append(npv)\n",
        "\n",
        "    mean_roc_auc_test.append(np.mean(roc_auc_test))\n",
        "    mean_sen_test.append(np.mean(sen_test))\n",
        "    mean_spec_test.append(np.mean(spec_test))\n",
        "    mean_f1_test.append(np.mean(f1_test))\n",
        "    mean_ppv_test.append(np.mean(ppv_test))\n",
        "    mean_npv_test.append(np.mean(npv_test))\n",
        "\n",
        "    model = LogisticRegression( max_iter=max_iter )\n",
        "\n",
        "    np.random.seed(rm)\n",
        "    model.fit(x, y[:,1])\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "    cMatrix = confusion_matrix(y_validate[:,1].astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate[:,1], y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate[:,1], new_y)\n",
        "    ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Mean area under the ROC curve = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_roc_auc_test),\n",
        "                                                                       np.mean (mean_roc_auc_test) -\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test)) ,\n",
        "                                                                       np.mean (mean_roc_auc_test) +\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test) )\n",
        "                                                                             ))\n",
        "print('Mean Sensitivity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen_test),\n",
        "                                                                       np.mean (mean_sen_test) -\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test)) ,\n",
        "                                                                       np.mean (mean_sen_test) +\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test))\n",
        "                                                                               ))\n",
        "print('Mean Specificity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec_test),\n",
        "                                                                       np.mean (mean_spec_test) - 1.96 * np.std(mean_spec_test) /np.sqrt(len(mean_spec_test)),\n",
        "                                                                       np.mean (mean_spec_test) + 1.96 * np.std(mean_spec_test)/np.sqrt(len(mean_spec_test) ))\n",
        "                                                                            )\n",
        "print('Mean F1-score ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1_test),\n",
        "                                                                       np.mean (mean_f1_test) - 1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test)) ,\n",
        "                                                                       np.mean (mean_f1_test) +\n",
        "                                                                       1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean PPV ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv_test),\n",
        "                                                                       np.mean (mean_ppv_test) -\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test)) ,\n",
        "                                                                       np.mean (mean_ppv_test) +\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean NPV  ={:.4f} 95% [ {:.4f}, {:.4f}]'.format(np.mean (mean_npv_test),\n",
        "                                                                   np.mean (mean_npv_test) -\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)),\n",
        "                                                                   np.mean (mean_npv_test) +\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)))\n",
        "                                                                  )\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )\n"
      ],
      "metadata": {
        "id": "KkQCWP4uAOM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Centroid (Table 4)\n",
        "\n"
      ],
      "metadata": {
        "id": "JEnR1BiEArJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='cat Age'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=64 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 64 ),(name)]= 0\n",
        "\n",
        "name='cat RAD'\n",
        "data[name]=None\n",
        "data.loc[(data['RAD, cm'] >= 3.33 ) , (name)]= 1\n",
        "data.loc[(data['RAD, cm'] < 3.33 ) , (name)]= 0\n",
        "\n",
        "name='cat LV ESD'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 4.4), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 4.4 ),(name)]= 0\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[(data['QRS, ms\\n'] < 80),(name)]= 1\n",
        "data.loc[(data['QRS, ms\\n'] >= 80 ),(name)]= 0\n",
        "\n",
        "name='cat QT'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 390),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 390 ),(name)]= 0\n",
        "\n",
        "name='cat PQ'\n",
        "data[name]=None\n",
        "data.loc[(data['PQ, ms\\n'] >= 155 ), (name)]= 1\n",
        "data.loc[(data['PQ, ms\\n'] < 155 ), (name)]= 0\n",
        "\n",
        "name='cat RR'\n",
        "data[name]=None\n",
        "data.loc[ (data['RR, ms\\n'] >= 925), (name)]= 1\n",
        "data.loc[ (data['RR, ms\\n'] < 925), (name)]= 0\n",
        "\n",
        "name='cat P'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 100),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 100 ),(name)]= 0\n",
        "\n",
        "\n",
        "features =[ 'cat Age',  'cat RAD' , 'Tricuspid regurgitation' ,  'cat QRS' , 'cat QT', 'cat RR' ,'cat PQ', 'cat P' ,  'cat LV ESD'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.185\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10\n",
        "\n",
        "np.random.seed(rm)\n",
        "\n",
        "########### LogisticRegression\n",
        "max_iter=100\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "\n",
        "for j in range(100):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "    # We set aside 20% for final testing\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data[features],model_data[y_name],\n",
        "                                                          train_size=0.8,\n",
        "                                                          stratify=model_data[y_name],\n",
        "                                                          random_state = rm )\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x_validate = np.array(x_validate)\n",
        "    y_validate = utils.to_categorical(y_validate)\n",
        "\n",
        "    roc_auc_test=[]\n",
        "    sen_test=[]\n",
        "    spec_test=[]\n",
        "    matr_test=[]\n",
        "    f1_test=[]\n",
        "    ppv_test=[]\n",
        "    npv_test=[]\n",
        "    threshold_test=[]\n",
        "    skf = StratifiedKFold(n_splits=n_splits )\n",
        "\n",
        "    # training and cross-validation\n",
        "    for i, (train_index, test_index) in enumerate(skf.split(x, y[:,1])):\n",
        "\n",
        "        x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "        y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "        model = LogisticRegression( max_iter=max_iter )\n",
        "\n",
        "        np.random.seed(rm)\n",
        "        model.fit(x_train, y_train[:,1])\n",
        "        y_pred_log=model.predict_proba(x_test)\n",
        "        new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "        new_y = np.array(new_y)\n",
        "        cMatrix = confusion_matrix(y_test[:,1].astype(\"int\"), new_y)\n",
        "        sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "        specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "        sen_test.append(sensivity)\n",
        "        spec_test.append(specifity)\n",
        "        fpr,tpr,thresholds = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_test.append(roc_auc)\n",
        "        f1=f1_score(y_test[:,1], new_y)\n",
        "        f1_test.append(f1)\n",
        "        ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "        npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "        ppv_test.append(ppv)\n",
        "        npv_test.append(npv)\n",
        "\n",
        "    mean_roc_auc_test.append(np.mean(roc_auc_test))\n",
        "    mean_sen_test.append(np.mean(sen_test))\n",
        "    mean_spec_test.append(np.mean(spec_test))\n",
        "    mean_f1_test.append(np.mean(f1_test))\n",
        "    mean_ppv_test.append(np.mean(ppv_test))\n",
        "    mean_npv_test.append(np.mean(npv_test))\n",
        "\n",
        "    model = LogisticRegression( max_iter=max_iter )\n",
        "\n",
        "    np.random.seed(rm)\n",
        "    model.fit(x, y[:,1])\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "    cMatrix = confusion_matrix(y_validate[:,1].astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate[:,1], y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate[:,1], new_y)\n",
        "    ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    if (cMatrix[0][0] + cMatrix[1][0] ) > 0:\n",
        "      npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Mean area under the ROC curve = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_roc_auc_test),\n",
        "                                                                       np.mean (mean_roc_auc_test) -\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test)) ,\n",
        "                                                                       np.mean (mean_roc_auc_test) +\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test) )\n",
        "                                                                             ))\n",
        "print('Mean Sensitivity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen_test),\n",
        "                                                                       np.mean (mean_sen_test) -\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test)) ,\n",
        "                                                                       np.mean (mean_sen_test) +\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test))\n",
        "                                                                               ))\n",
        "print('Mean Specificity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec_test),\n",
        "                                                                       np.mean (mean_spec_test) - 1.96 * np.std(mean_spec_test) /np.sqrt(len(mean_spec_test)),\n",
        "                                                                       np.mean (mean_spec_test) + 1.96 * np.std(mean_spec_test)/np.sqrt(len(mean_spec_test) ))\n",
        "                                                                            )\n",
        "print('Mean F1-score ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1_test),\n",
        "                                                                       np.mean (mean_f1_test) - 1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test)) ,\n",
        "                                                                       np.mean (mean_f1_test) +\n",
        "                                                                       1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean PPV ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv_test),\n",
        "                                                                       np.mean (mean_ppv_test) -\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test)) ,\n",
        "                                                                       np.mean (mean_ppv_test) +\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean NPV  ={:.4f} 95% [ {:.4f}, {:.4f}]'.format(np.mean (mean_npv_test),\n",
        "                                                                   np.mean (mean_npv_test) -\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)),\n",
        "                                                                   np.mean (mean_npv_test) +\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)))\n",
        "                                                                  )\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )\n"
      ],
      "metadata": {
        "id": "TdWZRLmTArs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model SHAP (Table 4)"
      ],
      "metadata": {
        "id": "v6lQ27K7BcRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='cat Age'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=61 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 61 ),(name)]= 0\n",
        "\n",
        "name='cat LV ESD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['LV ESD, cm'] >= 3.1) & ((data['LV ESD, cm'] < 4.1)) ), (name)]= 1\n",
        "data.loc[( (data['LV ESD, cm'] < 3.1) | ((data['LV ESD, cm'] >= 4.1)) ), (name)]= 0\n",
        "\n",
        "name='cat LV ESD 2'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 5), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 5 ),(name)]= 0\n",
        "\n",
        "name='cat RAD'\n",
        "data[name]=None\n",
        "data.loc[( (data['RAD, cm'] >= 4.2) & ((data['RAD, cm'] < 5.3)) ), (name)]= 1\n",
        "data.loc[( (data['RAD, cm'] < 4.2) | ((data['RAD, cm'] >= 5.3)) ), (name)]= 0\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[(data['QRS, ms\\n'] >= 80),(name)]= 1\n",
        "data.loc[(data['QRS, ms\\n'] < 80 ),(name)]= 0\n",
        "\n",
        "name='cat QT'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 390),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 390 ),(name)]= 0\n",
        "\n",
        "name='cat PQ'\n",
        "data[name]=None\n",
        "data.loc[( (data['PQ, ms\\n'] >= 170) & ((data['PQ, ms\\n'] < 210)) ), (name)]= 1\n",
        "data.loc[( (data['PQ, ms\\n'] < 170) | ((data['PQ, ms\\n'] >= 210)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 700) & ((data['RR, ms\\n'] < 750)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 700) | ((data['RR, ms\\n'] >= 750)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 880) & ((data['RR, ms\\n'] < 1000)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 880) | ((data['RR, ms\\n'] >= 1000)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 3'\n",
        "data[name]=None\n",
        "data.loc[ (data['RR, ms\\n'] >= 1100), (name)]= 1\n",
        "data.loc[ (data['RR, ms\\n'] < 1100), (name)]= 0\n",
        "\n",
        "name='cat P'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 130),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 130 ),(name)]= 0\n",
        "\n",
        "\n",
        "features =[ 'cat Age',  'cat RAD', 'cat LV ESD 1', \"cat LV ESD 2\", 'cat QRS' , 'cat QT',\n",
        "            'cat RR 1', 'cat RR 2', 'cat RR 3', 'cat PQ', 'cat P', 'Tricuspid regurgitation'\n",
        "          ]\n",
        "rm = 100\n",
        "border = 0.18\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10\n",
        "\n",
        "np.random.seed(rm)\n",
        "\n",
        "########### LogisticRegression\n",
        "max_iter=100\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "\n",
        "for j in range(100):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "    # We set aside 20% for final testing\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data[features],model_data[y_name],\n",
        "                                                          train_size=0.8,\n",
        "                                                          stratify=model_data[y_name],\n",
        "                                                          random_state = rm )\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x_validate = np.array(x_validate)\n",
        "    y_validate = utils.to_categorical(y_validate)\n",
        "\n",
        "    roc_auc_test=[]\n",
        "    sen_test=[]\n",
        "    spec_test=[]\n",
        "    matr_test=[]\n",
        "    f1_test=[]\n",
        "    ppv_test=[]\n",
        "    npv_test=[]\n",
        "    threshold_test=[]\n",
        "    skf = StratifiedKFold(n_splits=n_splits )\n",
        "\n",
        "    # training and cross-validation\n",
        "    for i, (train_index, test_index) in enumerate(skf.split(x, y[:,1])):\n",
        "\n",
        "        x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "        y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "        model = LogisticRegression( max_iter=max_iter )\n",
        "\n",
        "        np.random.seed(rm)\n",
        "        model.fit(x_train, y_train[:,1])\n",
        "        y_pred_log=model.predict_proba(x_test)\n",
        "        new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "        new_y = np.array(new_y)\n",
        "        cMatrix = confusion_matrix(y_test[:,1].astype(\"int\"), new_y)\n",
        "        sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "        specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "        sen_test.append(sensivity)\n",
        "        spec_test.append(specifity)\n",
        "        fpr,tpr,thresholds = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_test.append(roc_auc)\n",
        "        f1=f1_score(y_test[:,1], new_y)\n",
        "        f1_test.append(f1)\n",
        "        ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "        if (cMatrix[0][0] + cMatrix[1][0] ) > 0:\n",
        "          npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "        ppv_test.append(ppv)\n",
        "        npv_test.append(npv)\n",
        "\n",
        "    mean_roc_auc_test.append(np.mean(roc_auc_test))\n",
        "    mean_sen_test.append(np.mean(sen_test))\n",
        "    mean_spec_test.append(np.mean(spec_test))\n",
        "    mean_f1_test.append(np.mean(f1_test))\n",
        "    mean_ppv_test.append(np.mean(ppv_test))\n",
        "    mean_npv_test.append(np.mean(npv_test))\n",
        "\n",
        "    model = LogisticRegression( max_iter=max_iter )\n",
        "\n",
        "    np.random.seed(rm)\n",
        "    model.fit(x, y[:,1])\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "    cMatrix = confusion_matrix(y_validate[:,1].astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate[:,1], y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate[:,1], new_y)\n",
        "    ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    if (cMatrix[0][0] + cMatrix[1][0] ) > 0:\n",
        "      npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Mean area under the ROC curve = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_roc_auc_test),\n",
        "                                                                       np.mean (mean_roc_auc_test) -\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test)) ,\n",
        "                                                                       np.mean (mean_roc_auc_test) +\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test) )\n",
        "                                                                             ))\n",
        "print('Mean Sensitivity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen_test),\n",
        "                                                                       np.mean (mean_sen_test) -\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test)) ,\n",
        "                                                                       np.mean (mean_sen_test) +\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test))\n",
        "                                                                               ))\n",
        "print('Mean Specificity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec_test),\n",
        "                                                                       np.mean (mean_spec_test) - 1.96 * np.std(mean_spec_test) /np.sqrt(len(mean_spec_test)),\n",
        "                                                                       np.mean (mean_spec_test) + 1.96 * np.std(mean_spec_test)/np.sqrt(len(mean_spec_test) ))\n",
        "                                                                            )\n",
        "print('Mean F1-score ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1_test),\n",
        "                                                                       np.mean (mean_f1_test) - 1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test)) ,\n",
        "                                                                       np.mean (mean_f1_test) +\n",
        "                                                                       1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean PPV ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv_test),\n",
        "                                                                       np.mean (mean_ppv_test) -\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test)) ,\n",
        "                                                                       np.mean (mean_ppv_test) +\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean NPV  ={:.4f} 95% [ {:.4f}, {:.4f}]'.format(np.mean (mean_npv_test),\n",
        "                                                                   np.mean (mean_npv_test) -\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)),\n",
        "                                                                   np.mean (mean_npv_test) +\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)))\n",
        "                                                                  )\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )\n"
      ],
      "metadata": {
        "id": "M3PLaBNVBclL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predictor weights (Table 5)"
      ],
      "metadata": {
        "id": "4kpvcXKqKh_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SHAP cutoff thresholds"
      ],
      "metadata": {
        "id": "jTqrnXBKKwD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='cat Age'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=61 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 61 ),(name)]= 0\n",
        "\n",
        "name='cat LV ESD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['LV ESD, cm'] >= 3.1) & ((data['LV ESD, cm'] < 4.1)) ), (name)]= 1\n",
        "data.loc[( (data['LV ESD, cm'] < 3.1) | ((data['LV ESD, cm'] >= 4.1)) ), (name)]= 0\n",
        "\n",
        "name='cat LV ESD 2'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 5), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 5 ),(name)]= 0\n",
        "\n",
        "name='cat RAD'\n",
        "data[name]=None\n",
        "data.loc[( (data['RAD, cm'] >= 4.2) & ((data['RAD, cm'] < 5.3)) ), (name)]= 1\n",
        "data.loc[( (data['RAD, cm'] < 4.2) | ((data['RAD, cm'] >= 5.3)) ), (name)]= 0\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[(data['QRS, ms\\n'] >= 80),(name)]= 1\n",
        "data.loc[(data['QRS, ms\\n'] < 80 ),(name)]= 0\n",
        "\n",
        "name='cat QT'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 390),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 390 ),(name)]= 0\n",
        "\n",
        "name='cat PQ'\n",
        "data[name]=None\n",
        "data.loc[( (data['PQ, ms\\n'] >= 170) & ((data['PQ, ms\\n'] < 210)) ), (name)]= 1\n",
        "data.loc[( (data['PQ, ms\\n'] < 170) | ((data['PQ, ms\\n'] >= 210)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 700) & ((data['RR, ms\\n'] < 750)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 700) | ((data['RR, ms\\n'] >= 750)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 880) & ((data['RR, ms\\n'] < 1100)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 880) | ((data['RR, ms\\n'] >= 1100)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 3'\n",
        "data[name]=None\n",
        "data.loc[ (data['RR, ms\\n'] >= 1100), (name)]= 1\n",
        "data.loc[ (data['RR, ms\\n'] < 1100), (name)]= 0\n",
        "\n",
        "name='cat P'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 130),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 130 ),(name)]= 0\n",
        "\n",
        "\n",
        "features =[ 'cat Age',  'cat RAD', 'cat LV ESD 1', \"cat LV ESD 2\", 'cat QRS' , 'cat QT',\n",
        "            'cat RR 1', 'cat RR 2', 'cat RR 3', 'cat PQ', 'cat P', 'Tricuspid regurgitation'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.2\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10\n",
        "\n",
        "np.random.seed(rm)\n",
        "\n",
        "logistReg = LogisticRegression()\n",
        "logistReg.fit( model_data[features].values, model_data[y_name].values )\n",
        "\n",
        "for i in range(0, len(logistReg.coef_[0])):\n",
        "  print( \"Feature: \" + features[i] + \", Weight: \" + str( logistReg.coef_[0][i] ) )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7ArdKhiKvQ1",
        "outputId": "4b519221-f225-4bbd-a3db-50f7dad51781"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature: cat Age, Weight: 0.6832867581742813\n",
            "Feature: cat RAD, Weight: 0.9170410657376464\n",
            "Feature: cat LV ESD 1, Weight: 0.9588301080327979\n",
            "Feature: cat LV ESD 2, Weight: 1.1545495548896885\n",
            "Feature: cat QRS, Weight: 0.25506632493746134\n",
            "Feature: cat QT, Weight: 0.5420264924976407\n",
            "Feature: cat RR 1, Weight: 1.1451430255750896\n",
            "Feature: cat RR 2, Weight: 0.911753615488855\n",
            "Feature: cat RR 3, Weight: 0.740143562159023\n",
            "Feature: cat PQ, Weight: 0.9803811120776253\n",
            "Feature: cat P, Weight: 1.33451060274336\n",
            "Feature: Tricuspid regurgitation, Weight: 0.7347620998913463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Multimetric categorization cutoff thresholds"
      ],
      "metadata": {
        "id": "79Iyl-FrPmTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='cat Age'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=60 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 60 ),(name)]= 0\n",
        "\n",
        "name='cat LV ESD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['LV ESD, cm'] >= 3.1) & ((data['LV ESD, cm'] < 4.1)) ), (name)]= 1\n",
        "data.loc[( (data['LV ESD, cm'] < 3.1) | ((data['LV ESD, cm'] >= 4.1)) ), (name)]= 0\n",
        "\n",
        "name='cat LV ESD 2'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 5), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 5 ),(name)]= 0\n",
        "\n",
        "name='cat RAD'\n",
        "data[name]=None\n",
        "data.loc[( (data['RAD, cm'] >= 4.2) & ((data['RAD, cm'] < 5.3)) ), (name)]= 1\n",
        "data.loc[( (data['RAD, cm'] < 4.2) | ((data['RAD, cm'] >= 5.3)) ), (name)]= 0\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[(data['QRS, ms\\n'] >= 80),(name)]= 1\n",
        "data.loc[(data['QRS, ms\\n'] < 80 ),(name)]= 0\n",
        "\n",
        "name='cat QT'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 390),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 390 ),(name)]= 0\n",
        "\n",
        "name='cat PQ'\n",
        "data[name]=None\n",
        "data.loc[( (data['PQ, ms\\n'] >= 170) & ((data['PQ, ms\\n'] < 210)) ), (name)]= 1\n",
        "data.loc[( (data['PQ, ms\\n'] < 170) | ((data['PQ, ms\\n'] >= 210)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 700) & ((data['RR, ms\\n'] < 750)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 700) | ((data['RR, ms\\n'] >= 750)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 880) & ((data['RR, ms\\n'] < 1100)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 880) | ((data['RR, ms\\n'] >= 1100)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 3'\n",
        "data[name]=None\n",
        "data.loc[ (data['RR, ms\\n'] >= 1100), (name)]= 1\n",
        "data.loc[ (data['RR, ms\\n'] < 1100), (name)]= 0\n",
        "\n",
        "name='cat P 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['P, ms'] >= 100) & ((data['P, ms'] < 130)) ), (name)]= 1\n",
        "data.loc[( (data['P, ms'] < 100) | ((data['P, ms'] >= 130)) ), (name)]= 0\n",
        "\n",
        "name='cat P 2'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 130),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 130 ),(name)]= 0\n",
        "\n",
        "\n",
        "features =[ 'cat Age',  'cat RAD', 'cat LV ESD 1', \"cat LV ESD 2\", 'cat QRS' , 'cat QT',\n",
        "            'cat RR 1', 'cat RR 2', 'cat RR 3', 'cat PQ', 'cat P 1', 'cat P 2', 'Tricuspid regurgitation'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.2\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10\n",
        "\n",
        "np.random.seed(rm)\n",
        "\n",
        "logistReg = LogisticRegression()\n",
        "logistReg.fit( model_data[features].values, model_data[y_name].values )\n",
        "\n",
        "for i in range(0, len(logistReg.coef_[0])):\n",
        "  print( \"Feature: \" + features[i] + \", Weight: \" + str( logistReg.coef_[0][i] ) )"
      ],
      "metadata": {
        "id": "9CdOFd6IPesC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Medians of the groups and the centroid cutoff thresholds"
      ],
      "metadata": {
        "id": "YMpC004HQ-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='cat Age 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['Age, years'] >= 63) & ((data['Age, years'] < 66)) ), (name)]= 1\n",
        "data.loc[( (data['Age, years'] < 63) | ((data['Age, years'] >= 66)) ), (name)]= 0\n",
        "name='cat Age 2'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=66 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 66 ),(name)]= 0\n",
        "\n",
        "name='cat LV ESD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['LV ESD, cm'] >= 3.3) & ((data['LV ESD, cm'] < 3.33)) ), (name)]= 1\n",
        "data.loc[( (data['LV ESD, cm'] < 3.3) | ((data['LV ESD, cm'] >= 3.33)) ), (name)]= 0\n",
        "name='cat LV ESD 2'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 3.33), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 3.33 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat RAD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RAD, cm'] >= 4.4) & ((data['RAD, cm'] < 4.5)) ), (name)]= 1\n",
        "data.loc[( (data['RAD, cm'] < 4.4) | ((data['RAD, cm'] >= 4.5)) ), (name)]= 0\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[(data['QRS, ms\\n'] >= 80),(name)]= 1\n",
        "data.loc[(data['QRS, ms\\n'] < 80 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat QT 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['QT, ms\\n'] >= 380) & ((data['QT, ms\\n'] < 400)) ), (name)]= 1\n",
        "data.loc[( (data['QT, ms\\n'] < 380) | ((data['QT, ms\\n'] >= 400)) ), (name)]= 0\n",
        "name='cat QT 2'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 400),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 400 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat PQ'\n",
        "data[name]=None\n",
        "data.loc[(data['PQ, ms\\n'] >= 155),(name)]= 1\n",
        "data.loc[(data['PQ, ms\\n'] < 155 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat RR 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 925) & ((data['RR, ms\\n'] < 950)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 925) | ((data['RR, ms\\n'] >= 950)) ), (name)]= 0\n",
        "name='cat RR 2'\n",
        "data[name]=None\n",
        "data.loc[(data['RR, ms\\n'] >= 950),(name)]= 1\n",
        "data.loc[(data['RR, ms\\n'] < 950),(name)]= 0\n",
        "\n",
        "name='cat P'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 100),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 100),(name)]= 0\n",
        "\n",
        "\n",
        "features =[ 'cat Age 1', 'cat Age 2',\n",
        "            'cat LV ESD 1', 'cat LV ESD 2', \"cat RAD 1\",  'cat QRS',\n",
        "            'cat QT 1', 'cat QT 2', 'cat PQ', 'cat RR 2', 'cat P', 'Tricuspid regurgitation'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.2\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10\n",
        "\n",
        "np.random.seed(rm)\n",
        "\n",
        "logistReg = LogisticRegression()\n",
        "logistReg.fit( model_data[features].values, model_data[y_name].values )\n",
        "\n",
        "for i in range(0, len(features)):\n",
        "  print( \"Feature: \" + features[i] + \", Weight: \" + str( logistReg.coef_[0][i] ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKd7IuOQRFzR",
        "outputId": "2ebdfc93-4b8f-465f-aaaf-d947e55ec56a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature: cat Age 1, Weight: 0.3969683346816919\n",
            "Feature: cat Age 2, Weight: 0.31724870109528286\n",
            "Feature: cat LV ESD 1, Weight: 0.6739879567045161\n",
            "Feature: cat LV ESD 2, Weight: 0.1803738942876293\n",
            "Feature: cat RAD 1, Weight: 0.361449017709421\n",
            "Feature: cat QRS, Weight: 0.3817288777289737\n",
            "Feature: cat QT 1, Weight: 0.17361282790739463\n",
            "Feature: cat QT 2, Weight: 0.5905688027144186\n",
            "Feature: cat PQ, Weight: 0.5965503502958382\n",
            "Feature: cat RR 2, Weight: 0.21964849836934633\n",
            "Feature: cat P, Weight: 1.2808633877782962\n",
            "Feature: Tricuspid regurgitation, Weight: 0.6842866175393167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Quartiles cutoff thresholds"
      ],
      "metadata": {
        "id": "GffA1xSGTmZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='cat Age 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['Age, years'] >= 58) & ((data['Age, years'] < 64)) ), (name)]= 1\n",
        "data.loc[( (data['Age, years'] < 58) | ((data['Age, years'] >= 64)) ), (name)]= 0\n",
        "name='cat Age 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['Age, years'] >= 64) & ((data['Age, years'] < 69)) ), (name)]= 1\n",
        "data.loc[( (data['Age, years'] < 64) | ((data['Age, years'] >= 69)) ), (name)]= 0\n",
        "name='cat Age 3'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=69 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 69 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat LV ESD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['LV ESD, cm'] >= 3.1) & ((data['LV ESD, cm'] < 3.3)) ), (name)]= 1\n",
        "data.loc[( (data['LV ESD, cm'] < 3.1) | ((data['LV ESD, cm'] >= 3.3)) ), (name)]= 0\n",
        "name='cat LV ESD 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['LV ESD, cm'] >= 3.3) & ((data['LV ESD, cm'] < 3.8)) ), (name)]= 1\n",
        "data.loc[( (data['LV ESD, cm'] < 3.3) | ((data['LV ESD, cm'] >= 3.8)) ), (name)]= 0\n",
        "name='cat LV ESD 3'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 3.8), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 3.8 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat RAD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RAD, cm'] >= 3.8) & ((data['RAD, cm'] < 4.3)) ), (name)]= 1\n",
        "data.loc[( (data['RAD, cm'] < 3.8) | ((data['RAD, cm'] >= 4.3)) ), (name)]= 0\n",
        "name='cat RAD 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['RAD, cm'] >= 4.3) & ((data['RAD, cm'] < 4.8)) ), (name)]= 1\n",
        "data.loc[( (data['RAD, cm'] < 4.3) | ((data['RAD, cm'] >= 4.8)) ), (name)]= 0\n",
        "name='cat RAD 3'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 4.8), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 4.8 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[( (data['QRS, ms\\n'] >= 80) & ((data['QRS, ms\\n'] < 100)) ), (name)]= 1\n",
        "data.loc[( (data['QRS, ms\\n'] < 80) | ((data['QRS, ms\\n'] >= 100)) ), (name)]= 0\n",
        "\n",
        "\n",
        "name='cat QT 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['QT, ms\\n'] >= 360) & ((data['QT, ms\\n'] < 395)) ), (name)]= 1\n",
        "data.loc[( (data['QT, ms\\n'] < 360) | ((data['QT, ms\\n'] >= 395)) ), (name)]= 0\n",
        "name='cat QT 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['QT, ms\\n'] >= 395) & ((data['QT, ms\\n'] < 420)) ), (name)]= 1\n",
        "data.loc[( (data['QT, ms\\n'] < 395) | ((data['QT, ms\\n'] >= 420)) ), (name)]= 0\n",
        "name='cat QT 3'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 420),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 420 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat RR 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 800) & ((data['RR, ms\\n'] < 920)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 800) | ((data['RR, ms\\n'] >= 920)) ), (name)]= 0\n",
        "name='cat RR 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 920) & ((data['RR, ms\\n'] < 1080)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 920) | ((data['RR, ms\\n'] >= 1080)) ), (name)]= 0\n",
        "name='cat RR 3'\n",
        "data[name]=None\n",
        "data.loc[(data['RR, ms\\n'] >= 1080),(name)]= 1\n",
        "data.loc[(data['RR, ms\\n'] < 1080),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat PQ 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['PQ, ms\\n'] >= 140) & ((data['PQ, ms\\n'] < 160)) ), (name)]= 1\n",
        "data.loc[( (data['PQ, ms\\n'] < 140) | ((data['PQ, ms\\n'] >= 160)) ), (name)]= 0\n",
        "name='cat PQ 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['PQ, ms\\n'] >= 160) & ((data['PQ, ms\\n'] < 180)) ), (name)]= 1\n",
        "data.loc[( (data['PQ, ms\\n'] < 160) | ((data['PQ, ms\\n'] >= 180)) ), (name)]= 0\n",
        "name='cat PQ 3'\n",
        "data[name]=None\n",
        "data.loc[(data['PQ, ms\\n'] >= 180),(name)]= 1\n",
        "data.loc[(data['PQ, ms\\n'] < 180 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat P'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 100),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 100),(name)]= 0\n",
        "\n",
        "\n",
        "features =[ 'cat Age 1', 'cat Age 2', 'cat Age 3',\n",
        "            'cat LV ESD 1', 'cat LV ESD 2', 'cat LV ESD 3', \"cat RAD 1\", 'cat RAD 2', 'cat QRS', 'cat QT 2', 'cat QT 3',\n",
        "            'cat RR 2', 'cat RR 3', 'cat PQ 2', 'cat PQ 3', 'cat P', 'Tricuspid regurgitation'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.2\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10\n",
        "\n",
        "np.random.seed(rm)\n",
        "\n",
        "logistReg = LogisticRegression()\n",
        "logistReg.fit( model_data[features].values, model_data[y_name].values )\n",
        "\n",
        "for i in range(0, len(features)):\n",
        "  print( \"Feature: \" + features[i] + \", Weight: \" + str( logistReg.coef_[0][i] ) )"
      ],
      "metadata": {
        "id": "_0tLvjskTuwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Development of models based on multi-level variables (Table 6)"
      ],
      "metadata": {
        "id": "pV-ZhzbJXjAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model SHAP"
      ],
      "metadata": {
        "id": "xH2W6j427TIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='cat Age'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=61 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 61 ),(name)]= 0\n",
        "\n",
        "name='cat LV ESD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['LV ESD, cm'] >= 3.1) & ((data['LV ESD, cm'] < 4.1)) ), (name)]= 1\n",
        "data.loc[( (data['LV ESD, cm'] < 3.1) | ((data['LV ESD, cm'] >= 4.1)) ), (name)]= 0\n",
        "\n",
        "name='cat LV ESD 2'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 5), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 5 ),(name)]= 0\n",
        "\n",
        "name='cat RAD'\n",
        "data[name]=None\n",
        "data.loc[( (data['RAD, cm'] >= 4.2) & ((data['RAD, cm'] < 5.3)) ), (name)]= 1\n",
        "data.loc[( (data['RAD, cm'] < 4.2) | ((data['RAD, cm'] >= 5.3)) ), (name)]= 0\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[(data['QRS, ms\\n'] >= 80),(name)]= 1\n",
        "data.loc[(data['QRS, ms\\n'] < 80 ),(name)]= 0\n",
        "\n",
        "name='cat QT'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 390),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 390 ),(name)]= 0\n",
        "\n",
        "name='cat PQ'\n",
        "data[name]=None\n",
        "data.loc[( (data['PQ, ms\\n'] >= 170) & ((data['PQ, ms\\n'] < 210)) ), (name)]= 1\n",
        "data.loc[( (data['PQ, ms\\n'] < 170) | ((data['PQ, ms\\n'] >= 210)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 700) & ((data['RR, ms\\n'] < 750)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 700) | ((data['RR, ms\\n'] >= 750)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 880) & ((data['RR, ms\\n'] < 1100)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 880) | ((data['RR, ms\\n'] >= 1100)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 3'\n",
        "data[name]=None\n",
        "data.loc[ (data['RR, ms\\n'] >= 1100), (name)]= 1\n",
        "data.loc[ (data['RR, ms\\n'] < 1100), (name)]= 0\n",
        "\n",
        "name='cat P'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 130),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 130 ),(name)]= 0\n",
        "\n",
        "\n",
        "features =[ 'cat Age',  'cat RAD', 'cat LV ESD 1', \"cat LV ESD 2\", 'cat QRS' , 'cat QT',\n",
        "            'cat RR 1', 'cat RR 2', 'cat RR 3', 'cat PQ', 'cat P', 'Tricuspid regurgitation'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.42\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10\n",
        "\n",
        "########### XGBoost\n",
        "lr=0.03\n",
        "m_d=2\n",
        "n_e=200\n",
        "spw=3\n",
        "child_weight=1\n",
        "sub=0.7\n",
        "max_step=1\n",
        "gam=2\n",
        "method ='exact'\n",
        "boost= 'gbtree'\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "\n",
        "for j in range(100):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "    # We set aside 20% for final testing\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data[features],model_data[y_name],\n",
        "                                                          train_size=0.8,\n",
        "                                                          stratify=model_data[y_name],\n",
        "                                                          random_state = rm )\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x_validate = np.array(x_validate)\n",
        "    y_validate = utils.to_categorical(y_validate)\n",
        "\n",
        "    roc_auc_test=[]\n",
        "    sen_test=[]\n",
        "    spec_test=[]\n",
        "    matr_test=[]\n",
        "    f1_test=[]\n",
        "    ppv_test=[]\n",
        "    npv_test=[]\n",
        "    threshold_test=[]\n",
        "    skf = StratifiedKFold(n_splits=n_splits )\n",
        "\n",
        "    # training and cross-validation\n",
        "    for i, (train_index, test_index) in enumerate(skf.split(x, y[:,1])):\n",
        "\n",
        "        x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "        y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "        model = xgb.XGBClassifier(learning_rate=lr,  eval_metric = \"auc\",\n",
        "                                      scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                                      verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                                      tree_method =method, max_delta_step=max_step, gamma=gam,\n",
        "                                      min_child_weight=child_weight,\n",
        "                                      subsample=sub, colsample_bylevel=1,\n",
        "                                      n_jobs=-1, use_label_encoder=False\n",
        "                                     )\n",
        "\n",
        "        np.random.seed(rm)\n",
        "        model.fit(x_train, y_train[:,1])\n",
        "        y_pred_log=model.predict_proba(x_test)\n",
        "        new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "        new_y = np.array(new_y)\n",
        "        cMatrix = confusion_matrix(y_test[:,1].astype(\"int\"), new_y)\n",
        "        sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "        specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "        sen_test.append(sensivity)\n",
        "        spec_test.append(specifity)\n",
        "        fpr,tpr,thresholds = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_test.append(roc_auc)\n",
        "        f1=f1_score(y_test[:,1], new_y)\n",
        "        f1_test.append(f1)\n",
        "        ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "        npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "        ppv_test.append(ppv)\n",
        "        npv_test.append(npv)\n",
        "\n",
        "    mean_roc_auc_test.append(np.mean(roc_auc_test))\n",
        "    mean_sen_test.append(np.mean(sen_test))\n",
        "    mean_spec_test.append(np.mean(spec_test))\n",
        "    mean_f1_test.append(np.mean(f1_test))\n",
        "    mean_ppv_test.append(np.mean(ppv_test))\n",
        "    mean_npv_test.append(np.mean(npv_test))\n",
        "\n",
        "    model = xgb.XGBClassifier(learning_rate=lr,  eval_metric = \"auc\",\n",
        "                                      scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                                      verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                                      tree_method =method, max_delta_step=max_step, gamma=gam,\n",
        "                                      min_child_weight=child_weight,\n",
        "                                      subsample=sub, colsample_bylevel=1,\n",
        "                                      n_jobs=-1, use_label_encoder=False\n",
        "                                     )\n",
        "\n",
        "    np.random.seed(rm)\n",
        "    model.fit(x, y[:,1])\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "    cMatrix = confusion_matrix(y_validate[:,1].astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate[:,1], y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate[:,1], new_y)\n",
        "    ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Mean area under the ROC curve = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_roc_auc_test),\n",
        "                                                                       np.mean (mean_roc_auc_test) -\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test)) ,\n",
        "                                                                       np.mean (mean_roc_auc_test) +\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test) )\n",
        "                                                                             ))\n",
        "print('Mean Sensitivity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen_test),\n",
        "                                                                       np.mean (mean_sen_test) -\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test)) ,\n",
        "                                                                       np.mean (mean_sen_test) +\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test))\n",
        "                                                                               ))\n",
        "print('Mean Specificity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec_test),\n",
        "                                                                       np.mean (mean_spec_test) - 1.96 * np.std(mean_spec_test) /np.sqrt(len(mean_spec_test)),\n",
        "                                                                       np.mean (mean_spec_test) + 1.96 * np.std(mean_spec_test)/np.sqrt(len(mean_spec_test) ))\n",
        "                                                                            )\n",
        "print('Mean F1-score ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1_test),\n",
        "                                                                       np.mean (mean_f1_test) - 1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test)) ,\n",
        "                                                                       np.mean (mean_f1_test) +\n",
        "                                                                       1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean PPV ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv_test),\n",
        "                                                                       np.mean (mean_ppv_test) -\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test)) ,\n",
        "                                                                       np.mean (mean_ppv_test) +\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean NPV  ={:.4f} 95% [ {:.4f}, {:.4f}]'.format(np.mean (mean_npv_test),\n",
        "                                                                   np.mean (mean_npv_test) -\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)),\n",
        "                                                                   np.mean (mean_npv_test) +\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)))\n",
        "                                                                  )\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )\n",
        "\n"
      ],
      "metadata": {
        "id": "5V7aSnj52nPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model multimetric categorization"
      ],
      "metadata": {
        "id": "YZMPsT_37Z7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='cat Age'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=60 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 60 ),(name)]= 0\n",
        "\n",
        "name='cat LV ESD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['LV ESD, cm'] >= 3.1) & ((data['LV ESD, cm'] < 4.1)) ), (name)]= 1\n",
        "data.loc[( (data['LV ESD, cm'] < 3.1) | ((data['LV ESD, cm'] >= 4.1)) ), (name)]= 0\n",
        "\n",
        "name='cat LV ESD 2'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 5), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 5 ),(name)]= 0\n",
        "\n",
        "name='cat RAD'\n",
        "data[name]=None\n",
        "data.loc[( (data['RAD, cm'] >= 4.2) & ((data['RAD, cm'] < 5.3)) ), (name)]= 1\n",
        "data.loc[( (data['RAD, cm'] < 4.2) | ((data['RAD, cm'] >= 5.3)) ), (name)]= 0\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[(data['QRS, ms\\n'] >= 80),(name)]= 1\n",
        "data.loc[(data['QRS, ms\\n'] < 80 ),(name)]= 0\n",
        "\n",
        "name='cat QT'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 390),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 390 ),(name)]= 0\n",
        "\n",
        "name='cat PQ'\n",
        "data[name]=None\n",
        "data.loc[( (data['PQ, ms\\n'] >= 170) & ((data['PQ, ms\\n'] < 210)) ), (name)]= 1\n",
        "data.loc[( (data['PQ, ms\\n'] < 170) | ((data['PQ, ms\\n'] >= 210)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 700) & ((data['RR, ms\\n'] < 750)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 700) | ((data['RR, ms\\n'] >= 750)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 880) & ((data['RR, ms\\n'] < 1100)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 880) | ((data['RR, ms\\n'] >= 1100)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 3'\n",
        "data[name]=None\n",
        "data.loc[ (data['RR, ms\\n'] >= 1100), (name)]= 1\n",
        "data.loc[ (data['RR, ms\\n'] < 1100), (name)]= 0\n",
        "\n",
        "name='cat P 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['P, ms'] >= 100) & ((data['P, ms'] < 130)) ), (name)]= 1\n",
        "data.loc[( (data['P, ms'] < 100) | ((data['P, ms'] >= 130)) ), (name)]= 0\n",
        "\n",
        "name='cat P 2'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 130),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 130 ),(name)]= 0\n",
        "\n",
        "\n",
        "features =[ 'cat Age',  'cat RAD', 'cat LV ESD 1', \"cat LV ESD 2\", 'cat QRS' , 'cat QT',\n",
        "            'cat RR 1', 'cat RR 2', 'cat RR 3', 'cat PQ', 'cat P 1', 'cat P 2', 'Tricuspid regurgitation'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.42\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10\n",
        "\n",
        "########### XGBoost\n",
        "lr=0.03\n",
        "m_d=2\n",
        "n_e=200\n",
        "spw=3\n",
        "child_weight=1\n",
        "sub=0.7\n",
        "max_step=1\n",
        "gam=2\n",
        "method ='exact'\n",
        "boost= 'gbtree'\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "\n",
        "for j in range(100):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "    # We set aside 20% for final testing\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data[features],model_data[y_name],\n",
        "                                                          train_size=0.8,\n",
        "                                                          stratify=model_data[y_name],\n",
        "                                                          random_state = rm )\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x_validate = np.array(x_validate)\n",
        "    y_validate = utils.to_categorical(y_validate)\n",
        "\n",
        "    roc_auc_test=[]\n",
        "    sen_test=[]\n",
        "    spec_test=[]\n",
        "    matr_test=[]\n",
        "    f1_test=[]\n",
        "    ppv_test=[]\n",
        "    npv_test=[]\n",
        "    threshold_test=[]\n",
        "    skf = StratifiedKFold(n_splits=n_splits )\n",
        "\n",
        "    # training and cross-validation\n",
        "    for i, (train_index, test_index) in enumerate(skf.split(x, y[:,1])):\n",
        "\n",
        "        x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "        y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "        model = xgb.XGBClassifier(learning_rate=lr,  eval_metric = \"auc\",\n",
        "                                      scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                                      verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                                      tree_method =method, max_delta_step=max_step, gamma=gam,\n",
        "                                      min_child_weight=child_weight,\n",
        "                                      subsample=sub, colsample_bylevel=1,\n",
        "                                      n_jobs=-1, use_label_encoder=False\n",
        "                                     )\n",
        "\n",
        "        np.random.seed(rm)\n",
        "        model.fit(x_train, y_train[:,1])\n",
        "        y_pred_log=model.predict_proba(x_test)\n",
        "        new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "        new_y = np.array(new_y)\n",
        "        cMatrix = confusion_matrix(y_test[:,1].astype(\"int\"), new_y)\n",
        "        sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "        specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "        sen_test.append(sensivity)\n",
        "        spec_test.append(specifity)\n",
        "        fpr,tpr,thresholds = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_test.append(roc_auc)\n",
        "        f1=f1_score(y_test[:,1], new_y)\n",
        "        f1_test.append(f1)\n",
        "        ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "        npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "        ppv_test.append(ppv)\n",
        "        npv_test.append(npv)\n",
        "\n",
        "    mean_roc_auc_test.append(np.mean(roc_auc_test))\n",
        "    mean_sen_test.append(np.mean(sen_test))\n",
        "    mean_spec_test.append(np.mean(spec_test))\n",
        "    mean_f1_test.append(np.mean(f1_test))\n",
        "    mean_ppv_test.append(np.mean(ppv_test))\n",
        "    mean_npv_test.append(np.mean(npv_test))\n",
        "\n",
        "    model = xgb.XGBClassifier(learning_rate=lr,  eval_metric = \"auc\",\n",
        "                                      scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                                      verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                                      tree_method =method, max_delta_step=max_step, gamma=gam,\n",
        "                                      min_child_weight=child_weight,\n",
        "                                      subsample=sub, colsample_bylevel=1,\n",
        "                                      n_jobs=-1, use_label_encoder=False\n",
        "                                     )\n",
        "\n",
        "    np.random.seed(rm)\n",
        "    model.fit(x, y[:,1])\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "    cMatrix = confusion_matrix(y_validate[:,1].astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate[:,1], y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate[:,1], new_y)\n",
        "    ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Mean area under the ROC curve = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_roc_auc_test),\n",
        "                                                                       np.mean (mean_roc_auc_test) -\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test)) ,\n",
        "                                                                       np.mean (mean_roc_auc_test) +\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test) )\n",
        "                                                                             ))\n",
        "print('Mean Sensitivity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen_test),\n",
        "                                                                       np.mean (mean_sen_test) -\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test)) ,\n",
        "                                                                       np.mean (mean_sen_test) +\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test))\n",
        "                                                                               ))\n",
        "print('Mean Specificity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec_test),\n",
        "                                                                       np.mean (mean_spec_test) - 1.96 * np.std(mean_spec_test) /np.sqrt(len(mean_spec_test)),\n",
        "                                                                       np.mean (mean_spec_test) + 1.96 * np.std(mean_spec_test)/np.sqrt(len(mean_spec_test) ))\n",
        "                                                                            )\n",
        "print('Mean F1-score ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1_test),\n",
        "                                                                       np.mean (mean_f1_test) - 1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test)) ,\n",
        "                                                                       np.mean (mean_f1_test) +\n",
        "                                                                       1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean PPV ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv_test),\n",
        "                                                                       np.mean (mean_ppv_test) -\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test)) ,\n",
        "                                                                       np.mean (mean_ppv_test) +\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean NPV  ={:.4f} 95% [ {:.4f}, {:.4f}]'.format(np.mean (mean_npv_test),\n",
        "                                                                   np.mean (mean_npv_test) -\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)),\n",
        "                                                                   np.mean (mean_npv_test) +\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)))\n",
        "                                                                  )\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )\n",
        "\n"
      ],
      "metadata": {
        "id": "sYCMYeg57NPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3PF4kfb16Pr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model medians of the groups and the centroid"
      ],
      "metadata": {
        "id": "YFK75fQu7sJi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ame='cat Age 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['Age, years'] >= 63) & ((data['Age, years'] < 66)) ), (name)]= 1\n",
        "data.loc[( (data['Age, years'] < 63) | ((data['Age, years'] >= 66)) ), (name)]= 0\n",
        "name='cat Age 2'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=66 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 66 ),(name)]= 0\n",
        "\n",
        "name='cat LV ESD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['LV ESD, cm'] >= 3.3) & ((data['LV ESD, cm'] < 3.35)) ), (name)]= 1\n",
        "data.loc[( (data['LV ESD, cm'] < 3.3) | ((data['LV ESD, cm'] >= 3.35)) ), (name)]= 0\n",
        "name='cat LV ESD 2'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 3.35), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 3.35 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat RAD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RAD, cm'] >= 4.3) & ((data['RAD, cm'] < 4.5)) ), (name)]= 1\n",
        "data.loc[( (data['RAD, cm'] < 4.3) | ((data['RAD, cm'] >= 4.5)) ), (name)]= 0\n",
        "name='cat RAD 2'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 4.5), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 4.5 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[(data['QRS, ms\\n'] >= 80),(name)]= 1\n",
        "data.loc[(data['QRS, ms\\n'] < 80 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat QT 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['QT, ms\\n'] >= 380) & ((data['QT, ms\\n'] < 400)) ), (name)]= 1\n",
        "data.loc[( (data['QT, ms\\n'] < 380) | ((data['QT, ms\\n'] >= 400)) ), (name)]= 0\n",
        "name='cat QT 2'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 400),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 400 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat PQ'\n",
        "data[name]=None\n",
        "data.loc[(data['PQ, ms\\n'] >= 160),(name)]= 1\n",
        "data.loc[(data['PQ, ms\\n'] < 160 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat RR 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 900) & ((data['RR, ms\\n'] < 950)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 900) | ((data['RR, ms\\n'] >= 950)) ), (name)]= 0\n",
        "name='cat RR 2'\n",
        "data[name]=None\n",
        "data.loc[(data['RR, ms\\n'] >= 950),(name)]= 1\n",
        "data.loc[(data['RR, ms\\n'] < 950),(name)]= 0\n",
        "\n",
        "name='cat P'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 100),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 100),(name)]= 0\n",
        "\n",
        "\n",
        "features =[ 'cat Age 1', 'cat Age 2',\n",
        "            'cat LV ESD 1', 'cat LV ESD 2', \"cat RAD 1\",  'cat QRS',\n",
        "            'cat QT 1', 'cat QT 2', 'cat PQ', 'cat RR 1', 'cat RR 2', 'cat P', 'Tricuspid regurgitation'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.39\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10\n",
        "\n",
        "########### XGBoost\n",
        "lr=0.03\n",
        "m_d=2\n",
        "n_e=200\n",
        "spw=3\n",
        "child_weight=1\n",
        "sub=0.7\n",
        "max_step=1\n",
        "gam=2\n",
        "method ='exact'\n",
        "boost= 'gbtree'\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "\n",
        "for j in range(100):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "    # We set aside 20% for final testing\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data[features],model_data[y_name],\n",
        "                                                          train_size=0.8,\n",
        "                                                          stratify=model_data[y_name],\n",
        "                                                          random_state = rm )\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x_validate = np.array(x_validate)\n",
        "    y_validate = utils.to_categorical(y_validate)\n",
        "\n",
        "    roc_auc_test=[]\n",
        "    sen_test=[]\n",
        "    spec_test=[]\n",
        "    matr_test=[]\n",
        "    f1_test=[]\n",
        "    ppv_test=[]\n",
        "    npv_test=[]\n",
        "    threshold_test=[]\n",
        "    skf = StratifiedKFold(n_splits=n_splits )\n",
        "\n",
        "    # training and cross-validation\n",
        "    for i, (train_index, test_index) in enumerate(skf.split(x, y[:,1])):\n",
        "\n",
        "        x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "        y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "        model = xgb.XGBClassifier(learning_rate=lr,  eval_metric = \"auc\",\n",
        "                                      scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                                      verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                                      tree_method =method, max_delta_step=max_step, gamma=gam,\n",
        "                                      min_child_weight=child_weight,\n",
        "                                      subsample=sub, colsample_bylevel=1,\n",
        "                                      n_jobs=-1, use_label_encoder=False\n",
        "                                     )\n",
        "\n",
        "        np.random.seed(rm)\n",
        "        model.fit(x_train, y_train[:,1])\n",
        "        y_pred_log=model.predict_proba(x_test)\n",
        "        new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "        new_y = np.array(new_y)\n",
        "        cMatrix = confusion_matrix(y_test[:,1].astype(\"int\"), new_y)\n",
        "        sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "        specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "        sen_test.append(sensivity)\n",
        "        spec_test.append(specifity)\n",
        "        fpr,tpr,thresholds = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_test.append(roc_auc)\n",
        "        f1=f1_score(y_test[:,1], new_y)\n",
        "        f1_test.append(f1)\n",
        "        ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "        npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "        ppv_test.append(ppv)\n",
        "        npv_test.append(npv)\n",
        "\n",
        "    mean_roc_auc_test.append(np.mean(roc_auc_test))\n",
        "    mean_sen_test.append(np.mean(sen_test))\n",
        "    mean_spec_test.append(np.mean(spec_test))\n",
        "    mean_f1_test.append(np.mean(f1_test))\n",
        "    mean_ppv_test.append(np.mean(ppv_test))\n",
        "    mean_npv_test.append(np.mean(npv_test))\n",
        "\n",
        "    model = xgb.XGBClassifier(learning_rate=lr,  eval_metric = \"auc\",\n",
        "                                      scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                                      verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                                      tree_method =method, max_delta_step=max_step, gamma=gam,\n",
        "                                      min_child_weight=child_weight,\n",
        "                                      subsample=sub, colsample_bylevel=1,\n",
        "                                      n_jobs=-1, use_label_encoder=False\n",
        "                                     )\n",
        "\n",
        "    np.random.seed(rm)\n",
        "    model.fit(x, y[:,1])\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "    cMatrix = confusion_matrix(y_validate[:,1].astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate[:,1], y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate[:,1], new_y)\n",
        "    ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Mean area under the ROC curve = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_roc_auc_test),\n",
        "                                                                       np.mean (mean_roc_auc_test) -\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test)) ,\n",
        "                                                                       np.mean (mean_roc_auc_test) +\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test) )\n",
        "                                                                             ))\n",
        "print('Mean Sensitivity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen_test),\n",
        "                                                                       np.mean (mean_sen_test) -\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test)) ,\n",
        "                                                                       np.mean (mean_sen_test) +\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test))\n",
        "                                                                               ))\n",
        "print('Mean Specificity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec_test),\n",
        "                                                                       np.mean (mean_spec_test) - 1.96 * np.std(mean_spec_test) /np.sqrt(len(mean_spec_test)),\n",
        "                                                                       np.mean (mean_spec_test) + 1.96 * np.std(mean_spec_test)/np.sqrt(len(mean_spec_test) ))\n",
        "                                                                            )\n",
        "print('Mean F1-score ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1_test),\n",
        "                                                                       np.mean (mean_f1_test) - 1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test)) ,\n",
        "                                                                       np.mean (mean_f1_test) +\n",
        "                                                                       1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean PPV ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv_test),\n",
        "                                                                       np.mean (mean_ppv_test) -\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test)) ,\n",
        "                                                                       np.mean (mean_ppv_test) +\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean NPV  ={:.4f} 95% [ {:.4f}, {:.4f}]'.format(np.mean (mean_npv_test),\n",
        "                                                                   np.mean (mean_npv_test) -\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)),\n",
        "                                                                   np.mean (mean_npv_test) +\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)))\n",
        "                                                                  )\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )\n",
        "\n"
      ],
      "metadata": {
        "id": "Ak4cBK4-7zVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gUUOEAYl77VU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model quartiles cutoff"
      ],
      "metadata": {
        "id": "vN42jOz97-vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name='cat Age 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['Age, years'] >= 58) & ((data['Age, years'] < 64)) ), (name)]= 1\n",
        "data.loc[( (data['Age, years'] < 58) | ((data['Age, years'] >= 64)) ), (name)]= 0\n",
        "name='cat Age 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['Age, years'] >= 64) & ((data['Age, years'] < 69)) ), (name)]= 1\n",
        "data.loc[( (data['Age, years'] < 64) | ((data['Age, years'] >= 69)) ), (name)]= 0\n",
        "name='cat Age 3'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=69 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 69 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat LV ESD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['LV ESD, cm'] >= 3.1) & ((data['LV ESD, cm'] < 3.3)) ), (name)]= 1\n",
        "data.loc[( (data['LV ESD, cm'] < 3.1) | ((data['LV ESD, cm'] >= 3.3)) ), (name)]= 0\n",
        "name='cat LV ESD 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['LV ESD, cm'] >= 3.3) & ((data['LV ESD, cm'] < 3.8)) ), (name)]= 1\n",
        "data.loc[( (data['LV ESD, cm'] < 3.3) | ((data['LV ESD, cm'] >= 3.8)) ), (name)]= 0\n",
        "name='cat LV ESD 3'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 3.8), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 3.8 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat RAD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RAD, cm'] >= 3.8) & ((data['RAD, cm'] < 4.3)) ), (name)]= 1\n",
        "data.loc[( (data['RAD, cm'] < 3.8) | ((data['RAD, cm'] >= 4.3)) ), (name)]= 0\n",
        "name='cat RAD 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['RAD, cm'] >= 4.3) & ((data['RAD, cm'] < 4.8)) ), (name)]= 1\n",
        "data.loc[( (data['RAD, cm'] < 4.3) | ((data['RAD, cm'] >= 4.8)) ), (name)]= 0\n",
        "name='cat RAD 3'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 4.8), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 4.8 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[( (data['QRS, ms\\n'] >= 80) & ((data['QRS, ms\\n'] < 100)) ), (name)]= 1\n",
        "data.loc[( (data['QRS, ms\\n'] < 80) | ((data['QRS, ms\\n'] >= 100)) ), (name)]= 0\n",
        "\n",
        "\n",
        "name='cat QT 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['QT, ms\\n'] >= 360) & ((data['QT, ms\\n'] < 395)) ), (name)]= 1\n",
        "data.loc[( (data['QT, ms\\n'] < 360) | ((data['QT, ms\\n'] >= 395)) ), (name)]= 0\n",
        "name='cat QT 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['QT, ms\\n'] >= 395) & ((data['QT, ms\\n'] < 420)) ), (name)]= 1\n",
        "data.loc[( (data['QT, ms\\n'] < 395) | ((data['QT, ms\\n'] >= 420)) ), (name)]= 0\n",
        "name='cat QT 3'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 420),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 420 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat RR 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 800) & ((data['RR, ms\\n'] < 920)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 800) | ((data['RR, ms\\n'] >= 920)) ), (name)]= 0\n",
        "name='cat RR 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 920) & ((data['RR, ms\\n'] < 1080)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 920) | ((data['RR, ms\\n'] >= 1080)) ), (name)]= 0\n",
        "name='cat RR 3'\n",
        "data[name]=None\n",
        "data.loc[(data['RR, ms\\n'] >= 1080),(name)]= 1\n",
        "data.loc[(data['RR, ms\\n'] < 1080),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat PQ 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['PQ, ms\\n'] >= 140) & ((data['PQ, ms\\n'] < 160)) ), (name)]= 1\n",
        "data.loc[( (data['PQ, ms\\n'] < 140) | ((data['PQ, ms\\n'] >= 160)) ), (name)]= 0\n",
        "name='cat PQ 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['PQ, ms\\n'] >= 160) & ((data['PQ, ms\\n'] < 180)) ), (name)]= 1\n",
        "data.loc[( (data['PQ, ms\\n'] < 160) | ((data['PQ, ms\\n'] >= 180)) ), (name)]= 0\n",
        "name='cat PQ 3'\n",
        "data[name]=None\n",
        "data.loc[(data['PQ, ms\\n'] >= 180),(name)]= 1\n",
        "data.loc[(data['PQ, ms\\n'] < 180 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat P'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 100),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 100),(name)]= 0\n",
        "\n",
        "\n",
        "features =[ 'cat Age 1', 'cat Age 2', 'cat Age 3',\n",
        "            'cat LV ESD 1', 'cat LV ESD 2', 'cat LV ESD 3', \"cat RAD 1\", 'cat RAD 2', 'cat QRS', 'cat QT 2', 'cat QT 3',\n",
        "            'cat RR 2', 'cat RR 3', 'cat PQ 2', 'cat PQ 3', 'cat P', 'Tricuspid regurgitation'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.40\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "features.remove(y_name)\n",
        "n_splits = 10\n",
        "\n",
        "########### XGBoost\n",
        "lr=0.03\n",
        "m_d=2\n",
        "n_e=200\n",
        "spw=3\n",
        "child_weight=1\n",
        "sub=0.7\n",
        "max_step=1\n",
        "gam=2\n",
        "method ='exact'\n",
        "boost= 'gbtree'\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "\n",
        "for j in range(100):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "    # We set aside 20% for final testing\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data[features],model_data[y_name],\n",
        "                                                          train_size=0.8,\n",
        "                                                          stratify=model_data[y_name],\n",
        "                                                          random_state = rm )\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x_validate = np.array(x_validate)\n",
        "    y_validate = utils.to_categorical(y_validate)\n",
        "\n",
        "    roc_auc_test=[]\n",
        "    sen_test=[]\n",
        "    spec_test=[]\n",
        "    matr_test=[]\n",
        "    f1_test=[]\n",
        "    ppv_test=[]\n",
        "    npv_test=[]\n",
        "    threshold_test=[]\n",
        "    skf = StratifiedKFold(n_splits=n_splits )\n",
        "\n",
        "    # training and cross-validation\n",
        "    for i, (train_index, test_index) in enumerate(skf.split(x, y[:,1])):\n",
        "\n",
        "        x_train, x_test = x[train_index,:], x[test_index,:]\n",
        "        y_train, y_test = y[train_index,:], y[test_index,:]\n",
        "\n",
        "        model = xgb.XGBClassifier(learning_rate=lr,  eval_metric = \"auc\",\n",
        "                                      scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                                      verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                                      tree_method =method, max_delta_step=max_step, gamma=gam,\n",
        "                                      min_child_weight=child_weight,\n",
        "                                      subsample=sub, colsample_bylevel=1,\n",
        "                                      n_jobs=-1, use_label_encoder=False\n",
        "                                     )\n",
        "\n",
        "        np.random.seed(rm)\n",
        "        model.fit(x_train, y_train[:,1])\n",
        "        y_pred_log=model.predict_proba(x_test)\n",
        "        new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "        new_y = np.array(new_y)\n",
        "        cMatrix = confusion_matrix(y_test[:,1].astype(\"int\"), new_y)\n",
        "        sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "        specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "        sen_test.append(sensivity)\n",
        "        spec_test.append(specifity)\n",
        "        fpr,tpr,thresholds = roc_curve(y_test[:,1], y_pred_log[:,1] )\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_test.append(roc_auc)\n",
        "        f1=f1_score(y_test[:,1], new_y)\n",
        "        f1_test.append(f1)\n",
        "        ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "        npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "        ppv_test.append(ppv)\n",
        "        npv_test.append(npv)\n",
        "\n",
        "    mean_roc_auc_test.append(np.mean(roc_auc_test))\n",
        "    mean_sen_test.append(np.mean(sen_test))\n",
        "    mean_spec_test.append(np.mean(spec_test))\n",
        "    mean_f1_test.append(np.mean(f1_test))\n",
        "    mean_ppv_test.append(np.mean(ppv_test))\n",
        "    mean_npv_test.append(np.mean(npv_test))\n",
        "\n",
        "    model = xgb.XGBClassifier(learning_rate=lr,  eval_metric = \"auc\",\n",
        "                                      scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                                      verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                                      tree_method =method, max_delta_step=max_step, gamma=gam,\n",
        "                                      min_child_weight=child_weight,\n",
        "                                      subsample=sub, colsample_bylevel=1,\n",
        "                                      n_jobs=-1, use_label_encoder=False\n",
        "                                     )\n",
        "\n",
        "    np.random.seed(rm)\n",
        "    model.fit(x, y[:,1])\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "    cMatrix = confusion_matrix(y_validate[:,1].astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate[:,1], y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate[:,1], new_y)\n",
        "    ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Mean area under the ROC curve = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_roc_auc_test),\n",
        "                                                                       np.mean (mean_roc_auc_test) -\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test)) ,\n",
        "                                                                       np.mean (mean_roc_auc_test) +\n",
        "                                                                              1.96 * np.std(mean_roc_auc_test)/np.sqrt(len(mean_roc_auc_test) )\n",
        "                                                                             ))\n",
        "print('Mean Sensitivity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen_test),\n",
        "                                                                       np.mean (mean_sen_test) -\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test)) ,\n",
        "                                                                       np.mean (mean_sen_test) +\n",
        "                                                                                1.96 * np.std(mean_sen_test)/np.sqrt(len(mean_sen_test))\n",
        "                                                                               ))\n",
        "print('Mean Specificity  ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec_test),\n",
        "                                                                       np.mean (mean_spec_test) - 1.96 * np.std(mean_spec_test) /np.sqrt(len(mean_spec_test)),\n",
        "                                                                       np.mean (mean_spec_test) + 1.96 * np.std(mean_spec_test)/np.sqrt(len(mean_spec_test) ))\n",
        "                                                                            )\n",
        "print('Mean F1-score ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1_test),\n",
        "                                                                       np.mean (mean_f1_test) - 1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test)) ,\n",
        "                                                                       np.mean (mean_f1_test) +\n",
        "                                                                       1.96 * np.std(mean_f1_test)/np.sqrt(len(mean_f1_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean PPV ={:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv_test),\n",
        "                                                                       np.mean (mean_ppv_test) -\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test)) ,\n",
        "                                                                       np.mean (mean_ppv_test) +\n",
        "                                                                  1.96 * np.std(mean_ppv_test)/np.sqrt(len(mean_ppv_test) ))\n",
        "                                                                      )\n",
        "\n",
        "print('Mean NPV  ={:.4f} 95% [ {:.4f}, {:.4f}]'.format(np.mean (mean_npv_test),\n",
        "                                                                   np.mean (mean_npv_test) -\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)),\n",
        "                                                                   np.mean (mean_npv_test) +\n",
        "                                                                   1.96 * np.std(mean_npv_test)/np.sqrt(len(mean_npv_test)))\n",
        "                                                                  )\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )\n",
        "\n"
      ],
      "metadata": {
        "id": "HHSVNtEJ8CLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##External validation (Table 7)\n"
      ],
      "metadata": {
        "id": "6HyVJG488QdL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data load"
      ],
      "metadata": {
        "id": "xoF_dgEV-BA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Open dataset\n",
        "data_valid = pd.read_excel(\"DataSet_Validate.xlsx\")\n",
        "print(data.shape)\n",
        "## How many POAF and POAF free\n",
        "end_point = 'Atrial fibrillation'\n",
        "print(data_valid[end_point].value_counts(dropna = False))\n",
        "print(data_valid[end_point].value_counts(dropna = False, normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aYRbs1s9yF4",
        "outputId": "44348c50-17f3-437b-c813-e80f125751fc"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1305, 74)\n",
            "Atrial fibrillation\n",
            "0    161\n",
            "1     39\n",
            "Name: count, dtype: int64\n",
            "Atrial fibrillation\n",
            "0    0.805\n",
            "1    0.195\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name='cat Age'\n",
        "data[name]=None\n",
        "data.loc[(data['Age, years'] >=60 ),(name)]= 1\n",
        "data.loc[(data['Age, years'] < 60 ),(name)]= 0\n",
        "\n",
        "name='cat LV ESD 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['LV ESD, cm'] >= 3.1) & ((data['LV ESD, cm'] < 4.1)) ), (name)]= 1\n",
        "data.loc[( (data['LV ESD, cm'] < 3.1) | ((data['LV ESD, cm'] >= 4.1)) ), (name)]= 0\n",
        "\n",
        "name='cat LV ESD 2'\n",
        "data[name]=None\n",
        "data.loc[(data['LV ESD, cm'] >= 5), (name)]= 1\n",
        "data.loc[(data['LV ESD, cm'] < 5 ),(name)]= 0\n",
        "\n",
        "name='cat RAD'\n",
        "data[name]=None\n",
        "data.loc[( (data['RAD, cm'] >= 4.2) & ((data['RAD, cm'] < 5.3)) ), (name)]= 1\n",
        "data.loc[( (data['RAD, cm'] < 4.2) | ((data['RAD, cm'] >= 5.3)) ), (name)]= 0\n",
        "\n",
        "name='cat QRS'\n",
        "data[name]=None\n",
        "data.loc[(data['QRS, ms\\n'] >= 80),(name)]= 1\n",
        "data.loc[(data['QRS, ms\\n'] < 80 ),(name)]= 0\n",
        "\n",
        "name='cat QT'\n",
        "data[name]=None\n",
        "data.loc[(data['QT, ms\\n'] >= 390),(name)]= 1\n",
        "data.loc[(data['QT, ms\\n'] < 390 ),(name)]= 0\n",
        "\n",
        "name='cat PQ'\n",
        "data[name]=None\n",
        "data.loc[( (data['PQ, ms\\n'] >= 170) & ((data['PQ, ms\\n'] < 210)) ), (name)]= 1\n",
        "data.loc[( (data['PQ, ms\\n'] < 170) | ((data['PQ, ms\\n'] >= 210)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 700) & ((data['RR, ms\\n'] < 750)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 700) | ((data['RR, ms\\n'] >= 750)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 2'\n",
        "data[name]=None\n",
        "data.loc[( (data['RR, ms\\n'] >= 880) & ((data['RR, ms\\n'] < 1100)) ), (name)]= 1\n",
        "data.loc[( (data['RR, ms\\n'] < 880) | ((data['RR, ms\\n'] >= 1100)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 3'\n",
        "data[name]=None\n",
        "data.loc[ (data['RR, ms\\n'] >= 1100), (name)]= 1\n",
        "data.loc[ (data['RR, ms\\n'] < 1100), (name)]= 0\n",
        "\n",
        "name='cat P 1'\n",
        "data[name]=None\n",
        "data.loc[( (data['P, ms'] >= 100) & ((data['P, ms'] < 130)) ), (name)]= 1\n",
        "data.loc[( (data['P, ms'] < 100) | ((data['P, ms'] >= 130)) ), (name)]= 0\n",
        "\n",
        "name='cat P 2'\n",
        "data[name]=None\n",
        "data.loc[(data['P, ms'] >= 130),(name)]= 1\n",
        "data.loc[(data['P, ms'] < 130 ),(name)]= 0\n",
        "\n",
        "\n",
        "name='cat Age'\n",
        "data_valid[name]=None\n",
        "data_valid.loc[(data_valid['Age, years'] >=60 ),(name)]= 1\n",
        "data_valid.loc[(data_valid['Age, years'] < 60 ),(name)]= 0\n",
        "\n",
        "name='cat LV ESD 1'\n",
        "data_valid[name]=None\n",
        "data_valid.loc[( (data_valid['LV ESD, cm'] >= 3.1) & ((data_valid['LV ESD, cm'] < 4.1)) ), (name)]= 1\n",
        "data_valid.loc[( (data_valid['LV ESD, cm'] < 3.1) | ((data_valid['LV ESD, cm'] >= 4.1)) ), (name)]= 0\n",
        "\n",
        "name='cat LV ESD 2'\n",
        "data_valid[name]=None\n",
        "data_valid.loc[(data_valid['LV ESD, cm'] >= 5), (name)]= 1\n",
        "data_valid.loc[(data_valid['LV ESD, cm'] < 5 ),(name)]= 0\n",
        "\n",
        "name='cat RAD'\n",
        "data_valid[name]=None\n",
        "data_valid.loc[( (data['RAD, cm'] >= 4.2) & ((data_valid['RAD, cm'] < 5.3)) ), (name)]= 1\n",
        "data_valid.loc[( (data['RAD, cm'] < 4.2) | ((data_valid['RAD, cm'] >= 5.3)) ), (name)]= 0\n",
        "\n",
        "name='cat QRS'\n",
        "data_valid[name]=None\n",
        "data_valid.loc[(data_valid['QRS, ms\\n'] >= 80),(name)]= 1\n",
        "data_valid.loc[(data_valid['QRS, ms\\n'] < 80 ),(name)]= 0\n",
        "\n",
        "name='cat QT'\n",
        "data_valid[name]=None\n",
        "data_valid.loc[(data_valid['QT, ms\\n'] >= 390),(name)]= 1\n",
        "data_valid.loc[(data_valid['QT, ms\\n'] < 390 ),(name)]= 0\n",
        "\n",
        "name='cat PQ'\n",
        "data_valid[name]=None\n",
        "data_valid.loc[( (data_valid['PQ, ms\\n'] >= 170) & ((data_valid['PQ, ms\\n'] < 210)) ), (name)]= 1\n",
        "data_valid.loc[( (data_valid['PQ, ms\\n'] < 170) | ((data_valid['PQ, ms\\n'] >= 210)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 1'\n",
        "data_valid[name]=None\n",
        "data_valid.loc[( (data_valid['RR, ms\\n'] >= 700) & ((data_valid['RR, ms\\n'] < 750)) ), (name)]= 1\n",
        "data_valid.loc[( (data_valid['RR, ms\\n'] < 700) | ((data_valid['RR, ms\\n'] >= 750)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 2'\n",
        "data_valid[name]=None\n",
        "data_valid.loc[( (data_valid['RR, ms\\n'] >= 880) & ((data_valid['RR, ms\\n'] < 1100)) ), (name)]= 1\n",
        "data_valid.loc[( (data_valid['RR, ms\\n'] < 880) | ((data_valid['RR, ms\\n'] >= 1100)) ), (name)]= 0\n",
        "\n",
        "name='cat RR 3'\n",
        "data_valid[name]=None\n",
        "data_valid.loc[ (data_valid['RR, ms\\n'] >= 1100), (name)]= 1\n",
        "data_valid.loc[ (data_valid['RR, ms\\n'] < 1100), (name)]= 0\n",
        "\n",
        "name='cat P 1'\n",
        "data_valid[name]=None\n",
        "data_valid.loc[( (data_valid['P, ms'] >= 100) & ((data_valid['P, ms'] < 130)) ), (name)]= 1\n",
        "data_valid.loc[( (data_valid['P, ms'] < 100) | ((data_valid['P, ms'] >= 130)) ), (name)]= 0\n",
        "\n",
        "name='cat P 2'\n",
        "data_valid[name]=None\n",
        "data_valid.loc[(data_valid['P, ms'] >= 130),(name)]= 1\n",
        "data_valid.loc[(data_valid['P, ms'] < 130 ),(name)]= 0"
      ],
      "metadata": {
        "id": "OCTWHOm2EkpX"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Continuous form of predictors"
      ],
      "metadata": {
        "id": "ZlCd76Hp-YBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Logistic regression"
      ],
      "metadata": {
        "id": "DXFmg0ylAM7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Data preparation\n",
        "features =[ 'Age, years',  'RAD, cm' , 'Tricuspid regurgitation' ,  'QRS, ms\\n' , 'QT, ms\\n', 'RR, ms\\n' ,'PQ, ms\\n', 'P, ms' ,  'LV ESD, cm'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.1775\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "model_data_valid = data_valid[features].dropna()\n",
        "features.remove(y_name)\n",
        "np.random.seed(rm)\n",
        "\n",
        "########### Logistic regression\n",
        "max_iter = 10000\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "x = model_data[features].values\n",
        "y = model_data[[y_name]].values\n",
        "\n",
        "model = LogisticRegression( max_iter=max_iter )\n",
        "np.random.seed(rm)\n",
        "model.fit(x, y)\n",
        "\n",
        "for j in range(2000):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data_valid[features].values,model_data_valid[y_name].values,\n",
        "                                                          train_size=0.95,\n",
        "                                                          stratify=model_data_valid[y_name],\n",
        "                                                          random_state = rm )\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "\n",
        "\n",
        "    cMatrix = confusion_matrix(y_validate.astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate, y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate, new_y)\n",
        "    if cMatrix[1][1] + cMatrix[0][1] > 0:\n",
        "      ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    else:\n",
        "      ppv = 0\n",
        "    if cMatrix[0][0] + cMatrix[1][0] > 0:\n",
        "      npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "    else:\n",
        "      npv=0\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFH9apH9AekF",
        "outputId": "2dbd6648-4f37-4c55-ffe3-3852481c833a"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validated area under the ROC curve = 0.6729 95% [ 0.6636, 0.6823]\n",
            "Validated Sensitivity  = 0.5597 95% [ 0.5446,  0.5749]\n",
            "Validated Specificity  = 0.6006 95% [ 0.5933,  0.6080]\n",
            "Validated F1-score  =  0.3481 95% [ 0.3387,  0.3576]\n",
            "Validated PPV  = 0.2636 95% [ 0.2557,  0.2715]\n",
            "Validated NPV  = 0.8498 95% [ 0.8446,  0.8551]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####XGBoost"
      ],
      "metadata": {
        "id": "lFVjMlSY_ye7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preparation\n",
        "features =[ 'Age, years',  'RAD, cm' , 'Tricuspid regurgitation' ,  'QRS, ms\\n' , 'QT, ms\\n', 'RR, ms\\n' ,'PQ, ms\\n', 'P, ms' ,  'LV ESD, cm'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.415\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "model_data_valid = data_valid[features].dropna()\n",
        "features.remove(y_name)\n",
        "np.random.seed(rm)\n",
        "\n",
        "########### XGBoost\n",
        "lr=0.03\n",
        "m_d=2\n",
        "n_e=50\n",
        "spw=3\n",
        "child_weight=1\n",
        "sub=0.5\n",
        "max_step=1\n",
        "gam=2\n",
        "method ='exact'\n",
        "boost= 'gbtree'\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "x = model_data[features].values\n",
        "y = model_data[[y_name]].values\n",
        "\n",
        "model = xgb.XGBClassifier(learning_rate=lr,  eval_metric = \"auc\",\n",
        "                                      scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                                      verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                                      tree_method =method, max_delta_step=max_step, gamma=gam,\n",
        "                                      min_child_weight=child_weight,\n",
        "                                      subsample=sub, colsample_bylevel=1,\n",
        "                                      n_jobs=-1, use_label_encoder=False\n",
        "                                     )\n",
        "np.random.seed(rm)\n",
        "model.fit(x, y)\n",
        "\n",
        "for j in range(2000):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data_valid[features],model_data_valid[y_name],\n",
        "                                                          train_size=0.95,\n",
        "                                                          stratify=model_data_valid[y_name],\n",
        "                                                          random_state = rm )\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "\n",
        "    cMatrix = confusion_matrix(y_validate.astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate, y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate, new_y)\n",
        "    if cMatrix[1][1] + cMatrix[0][1] > 0:\n",
        "      ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    else:\n",
        "      ppv = 0\n",
        "    if cMatrix[0][0] + cMatrix[1][0] > 0:\n",
        "      npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "    else:\n",
        "      ppv = 0\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfpj9sES-iin",
        "outputId": "4671ddc0-6c6a-4acc-f8d2-5fc5b5b17713"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validated area under the ROC curve = 0.7870 95% [ 0.7793, 0.7946]\n",
            "Validated Sensitivity  = 0.6983 95% [ 0.6842,  0.7123]\n",
            "Validated Specificity  = 0.6885 95% [ 0.6813,  0.6957]\n",
            "Validated F1-score  =  0.4758 95% [ 0.4662,  0.4853]\n",
            "Validated PPV  = 0.3845 95% [ 0.3751,  0.3938]\n",
            "Validated NPV  = 0.9075 95% [ 0.9031,  0.9118]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Random Forest"
      ],
      "metadata": {
        "id": "ZLNCTMMmAI3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preparation\n",
        "features =[ 'Age, years',  'RAD, cm' , 'Tricuspid regurgitation' ,  'QRS, ms\\n' , 'QT, ms\\n', 'RR, ms\\n' ,'PQ, ms\\n', 'P, ms' ,  'LV ESD, cm'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.20\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "model_data_valid = data_valid[features].dropna()\n",
        "features.remove(y_name)\n",
        "np.random.seed(rm)\n",
        "\n",
        "########### Random Forest\n",
        "m_d1=2 #8\n",
        "n_e1=100  #110\n",
        "min_leaf = 0.01 #0.01\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "x = model_data[features].values\n",
        "y = model_data[[y_name]].values\n",
        "\n",
        "model = RandomForestClassifier(random_state=rm, n_estimators=n_e1, max_depth=m_d1\n",
        "                                          ,min_samples_leaf = min_leaf\n",
        "                                          )\n",
        "np.random.seed(rm)\n",
        "model.fit(x, y)\n",
        "\n",
        "for j in range(2000):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data_valid[features].values,model_data_valid[y_name].values,\n",
        "                                                          train_size=0.95,\n",
        "                                                          stratify=model_data_valid[y_name],\n",
        "                                                          random_state = rm )\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "\n",
        "    cMatrix = confusion_matrix(y_validate.astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate, y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate, new_y)\n",
        "    if cMatrix[1][1] + cMatrix[0][1] > 0:\n",
        "      ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    else:\n",
        "      ppv = 0\n",
        "    if cMatrix[0][0] + cMatrix[1][0] > 0:\n",
        "      npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "    else:\n",
        "      ppv = 0\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbYH1G6zAd2N",
        "outputId": "055594b6-2fd6-47df-a0d6-f04223c067cd"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validated area under the ROC curve = 0.7656 95% [ 0.7575, 0.7738]\n",
            "Validated Sensitivity  = 0.7650 95% [ 0.7519,  0.7781]\n",
            "Validated Specificity  = 0.6442 95% [ 0.6371,  0.6514]\n",
            "Validated F1-score  =  0.4842 95% [ 0.4756,  0.4927]\n",
            "Validated PPV  = 0.3700 95% [ 0.3622,  0.3778]\n",
            "Validated NPV  = 0.9232 95% [ 0.9188,  0.9275]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Categorized form of predictors"
      ],
      "metadata": {
        "id": "KbX6JlP7BfKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Logistic regression"
      ],
      "metadata": {
        "id": "-Oj1BpDGCMUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preparation\n",
        "features =[ 'cat Age',  'cat RAD', 'cat LV ESD 1', \"cat LV ESD 2\", 'cat QRS' , 'cat QT',\n",
        "            'cat RR 1', 'cat RR 2', 'cat RR 3', 'cat PQ', 'cat P 1', 'cat P 2', 'Tricuspid regurgitation'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.22\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "model_data_valid = data_valid[features].dropna()\n",
        "features.remove(y_name)\n",
        "np.random.seed(rm)\n",
        "\n",
        "########### Logistic regression\n",
        "max_iter = 10000\n",
        "\n",
        "mean_roc_auc_test = []\n",
        "mean_sen_test = []\n",
        "mean_spec_test = []\n",
        "mean_f1_test = []\n",
        "mean_ppv_test = []\n",
        "mean_npv_test = []\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "x = model_data[features].values\n",
        "y = model_data[[y_name]].values\n",
        "\n",
        "model = LogisticRegression( max_iter=max_iter )\n",
        "np.random.seed(rm)\n",
        "model.fit(x, y)\n",
        "\n",
        "for j in range(2000):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data_valid[features].values,model_data_valid[y_name].values,\n",
        "                                                          train_size=0.95,\n",
        "                                                          stratify=model_data_valid[y_name],\n",
        "                                                          random_state = rm )\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "\n",
        "\n",
        "    cMatrix = confusion_matrix(y_validate.astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate, y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate, new_y)\n",
        "    if cMatrix[1][1] + cMatrix[0][1] > 0:\n",
        "      ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    else:\n",
        "      ppv = 0\n",
        "    npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gIpKqQ3CUpk",
        "outputId": "3d25675a-19cc-417d-89f1-efdf9b4630ff"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validated area under the ROC curve = 0.7725 95% [ 0.7643, 0.7807]\n",
            "Validated Sensitivity  = 0.7093 95% [ 0.6951,  0.7234]\n",
            "Validated Specificity  = 0.6929 95% [ 0.6859,  0.6999]\n",
            "Validated F1-score  =  0.4849 95% [ 0.4751,  0.4948]\n",
            "Validated PPV  = 0.3905 95% [ 0.3811,  0.3999]\n",
            "Validated NPV  = 0.9107 95% [ 0.9064,  0.9151]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####XGBoost"
      ],
      "metadata": {
        "id": "ksi5uktCBwLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preparation\n",
        "features =[ 'cat Age',  'cat RAD', 'cat LV ESD 1', \"cat LV ESD 2\", 'cat QRS' , 'cat QT',\n",
        "            'cat RR 1', 'cat RR 2', 'cat RR 3', 'cat PQ', 'cat P 1', 'cat P 2', 'Tricuspid regurgitation'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.445\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "model_data_valid = data_valid[features].dropna()\n",
        "model_data_valid = model_data_valid.astype( int )\n",
        "features.remove(y_name)\n",
        "np.random.seed(rm)\n",
        "\n",
        "########### XGBoost\n",
        "lr=0.03\n",
        "m_d=2\n",
        "n_e=100\n",
        "spw=3\n",
        "child_weight=1\n",
        "sub=0.5\n",
        "max_step=1\n",
        "gam=2\n",
        "method ='exact'\n",
        "boost= 'gbtree'\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "x = model_data[features].values\n",
        "y = model_data[[y_name]].values\n",
        "\n",
        "model = xgb.XGBClassifier(learning_rate=lr,  eval_metric = \"auc\",\n",
        "                                      scale_pos_weight = spw,    max_depth=m_d,  n_estimators=n_e,  random_state=rm,\n",
        "                                      verbosity=0 , objective= 'binary:logistic', booster= boost,\n",
        "                                      tree_method =method, max_delta_step=max_step, gamma=gam,\n",
        "                                      min_child_weight=child_weight,\n",
        "                                      subsample=sub, colsample_bylevel=1,\n",
        "                                      n_jobs=-1, use_label_encoder=False\n",
        "                                     )\n",
        "np.random.seed(rm)\n",
        "model.fit(x, y)\n",
        "\n",
        "for j in range(2000):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data_valid[features],model_data_valid[y_name],\n",
        "                                                          train_size=0.95,\n",
        "                                                          stratify=model_data_valid[y_name],\n",
        "                                                          random_state = rm )\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "\n",
        "\n",
        "    cMatrix = confusion_matrix(y_validate.astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate, y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate, new_y)\n",
        "    if cMatrix[1][1] + cMatrix[0][1] > 0:\n",
        "      ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    else:\n",
        "      ppv = 0\n",
        "    if cMatrix[0][0] + cMatrix[1][0] > 0:\n",
        "      npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "    else:\n",
        "      ppv = 0\n",
        "\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )"
      ],
      "metadata": {
        "id": "Gtw90uh2Cawu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72eaf7d7-0c30-4c4d-f36f-4ce371cd6c82"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validated area under the ROC curve = 0.7747 95% [ 0.7667, 0.7828]\n",
            "Validated Sensitivity  = 0.7147 95% [ 0.7007,  0.7288]\n",
            "Validated Specificity  = 0.7169 95% [ 0.7102,  0.7237]\n",
            "Validated F1-score  =  0.5043 95% [ 0.4941,  0.5145]\n",
            "Validated PPV  = 0.4135 95% [ 0.4035,  0.4236]\n",
            "Validated NPV  = 0.9153 95% [ 0.9111,  0.9194]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Random Forest"
      ],
      "metadata": {
        "id": "IuP8rL2JCR8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preparation\n",
        "features =[ 'cat Age',  'cat RAD', 'cat LV ESD 1', \"cat LV ESD 2\", 'cat QRS' , 'cat QT',\n",
        "            'cat RR 1', 'cat RR 2', 'cat RR 3', 'cat PQ', 'cat P 1', 'cat P 2', 'Tricuspid regurgitation'\n",
        "          ]\n",
        "y_name = \"Atrial fibrillation\"\n",
        "rm = 100\n",
        "border = 0.225\n",
        "np.random.seed(rm)\n",
        "features.append(y_name)\n",
        "model_data = data[features].dropna()\n",
        "model_data_valid = data_valid[features].dropna()\n",
        "features.remove(y_name)\n",
        "np.random.seed(rm)\n",
        "\n",
        "########### Random Forest\n",
        "m_d1=2 #8\n",
        "n_e1=100  #110\n",
        "min_leaf = 0.01 #0.01\n",
        "\n",
        "mean_roc_auc = []\n",
        "mean_sen = []\n",
        "mean_spec = []\n",
        "mean_f1 = []\n",
        "mean_ppv = []\n",
        "mean_npv = []\n",
        "\n",
        "x = model_data[features].values\n",
        "y = model_data[[y_name]].values\n",
        "\n",
        "model = RandomForestClassifier(random_state=rm, n_estimators=n_e1, max_depth=m_d1\n",
        "                                          ,min_samples_leaf = min_leaf\n",
        "                                          )\n",
        "np.random.seed(rm)\n",
        "model.fit(x, y)\n",
        "\n",
        "for j in range(2000):\n",
        "    rm=j+42\n",
        "    np.random.seed(rm)\n",
        "\n",
        "    x = np.array(x)\n",
        "    y = utils.to_categorical(y)\n",
        "    x, x_validate, y, y_validate = train_test_split(      model_data_valid[features].values,model_data_valid[y_name].values,\n",
        "                                                          train_size=0.95,\n",
        "                                                          stratify=model_data_valid[y_name],\n",
        "                                                          random_state = rm )\n",
        "\n",
        "    y_pred_log=model.predict_proba(x_validate)\n",
        "    new_y =np.where(y_pred_log[:,1] >=border, 1, 0)\n",
        "    new_y = np.array(new_y)\n",
        "\n",
        "    cMatrix = confusion_matrix(y_validate.astype(\"int\"), new_y)\n",
        "    sensivity = cMatrix[1][1]/(cMatrix[1][0] + cMatrix[1][1])\n",
        "    specifity = cMatrix[0][0]/(cMatrix[0][0] + cMatrix[0][1])\n",
        "    fpr,tpr,_ = roc_curve(y_validate, y_pred_log[:,1] )\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    f1=f1_score(y_validate, new_y)\n",
        "    if cMatrix[1][1] + cMatrix[0][1] > 0:\n",
        "      ppv=cMatrix[1][1]/ (cMatrix[1][1] + cMatrix[0][1])\n",
        "    else:\n",
        "      ppv = 0\n",
        "    if cMatrix[0][0] + cMatrix[1][0] > 0:\n",
        "      npv=cMatrix[0][0] / (cMatrix[0][0] + cMatrix[1][0] )\n",
        "    else:\n",
        "      ppv = 0\n",
        "\n",
        "    mean_roc_auc.append(roc_auc)\n",
        "    mean_sen.append(sensivity)\n",
        "    mean_spec.append(specifity)\n",
        "    mean_f1.append(f1)\n",
        "    mean_ppv.append(ppv)\n",
        "    mean_npv.append(npv)\n",
        "\n",
        "print('Validated area under the ROC curve = {:.4f} 95% [ {:.4f}, {:.4f}]'.format(\n",
        "    np.mean (mean_roc_auc),  np.mean (mean_roc_auc) -\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) ,\n",
        "    np.mean (mean_roc_auc) +\n",
        "    1.96 * np.std(mean_roc_auc)/np.sqrt(len(mean_roc_auc)) )\n",
        "                                                                                             )\n",
        "\n",
        "print('Validated Sensitivity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_sen),\n",
        "                                                                       np.mean (mean_sen) -\n",
        "                                                                                        1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen)) ,\n",
        "                                                                       np.mean (mean_sen) + 1.96 * np.std(mean_sen)/np.sqrt(len(mean_sen))\n",
        "                                                                                       ))\n",
        "print('Validated Specificity  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_spec),\n",
        "                                                                       np.mean (mean_spec) -\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec)) ,\n",
        "                                                                       np.mean (mean_spec) +\n",
        "                                                                                     1.96 * np.std(mean_spec)/np.sqrt(len(mean_spec))\n",
        "                                                                                    ))\n",
        "print('Validated F1-score  =  {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_f1),\n",
        "                                                                       np.mean (mean_f1) - 1.96 * np.std(mean_f1)/np.sqrt(len(mean_f1)) ,\n",
        "                                                                       np.mean (mean_f1) + 1.96 * np.std(mean_f1) /np.sqrt(len(mean_f1))\n",
        "                                                                                ))\n",
        "print('Validated PPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(np.mean (mean_ppv),\n",
        "                                                                       np.mean (mean_ppv) - 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv)) ,\n",
        "                                                                       np.mean (mean_ppv) + 1.96 * np.std(mean_ppv)/np.sqrt(len(mean_ppv))\n",
        "                                                                          ))\n",
        "print('Validated NPV  = {:.4f} 95% [ {:.4f},  {:.4f}]'.format(\n",
        "    np.mean (mean_npv), np.mean (mean_npv) -\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv)) ,\n",
        "    np.mean (mean_npv) +\n",
        "    1.96 * np.std(mean_npv)/np.sqrt(len(mean_npv) ))\n",
        "     )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3omSHfHeCeJU",
        "outputId": "84de1082-c002-4a18-b365-43f52080049a"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validated area under the ROC curve = 0.7572 95% [ 0.7491, 0.7653]\n",
            "Validated Sensitivity  = 0.7147 95% [ 0.7007,  0.7288]\n",
            "Validated Specificity  = 0.7039 95% [ 0.6971,  0.7106]\n",
            "Validated F1-score  =  0.4945 95% [ 0.4846,  0.5044]\n",
            "Validated PPV  = 0.4001 95% [ 0.3905,  0.4096]\n",
            "Validated NPV  = 0.9138 95% [ 0.9095,  0.9180]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:carina]",
      "language": "python",
      "name": "conda-env-carina-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kWulCAn1dhmX",
        "mvFNJ2m8yQ0d",
        "CUkQAYVIdhma",
        "HKnHvbrWdhmc",
        "t5DsW0c3pldN",
        "ph306kBjC58v",
        "uDavw-UTDIoc",
        "9RUYrALsDLqY",
        "x3K6ILpvDQVm",
        "v1JXA0AUdhmj",
        "nKLqjgdDQiNw",
        "Hurgt59CU0oJ",
        "63W79_2uypTC",
        "bgg50OPD1Spw",
        "NFo4macxAOfu",
        "4kpvcXKqKh_V",
        "jTqrnXBKKwD5",
        "YMpC004HQ-bR",
        "GffA1xSGTmZJ",
        "pV-ZhzbJXjAP",
        "xH2W6j427TIl",
        "YZMPsT_37Z7Y",
        "YFK75fQu7sJi",
        "vN42jOz97-vt",
        "xoF_dgEV-BA_",
        "ZlCd76Hp-YBq",
        "KbX6JlP7BfKh",
        "-Oj1BpDGCMUQ",
        "ksi5uktCBwLw",
        "IuP8rL2JCR8N"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}